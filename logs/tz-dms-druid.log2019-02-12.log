[druid] 2019-02-12 09:39:28,768 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 09:39:28,795 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 09:39:29,829 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 09:39:29,901 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 09:39:30,085 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 09:39:30,209 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 09:39:30,649 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1058512454_0001
   [druid] 2019-02-12 09:39:31,004 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 09:39:31,005 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1058512454_0001
   [druid] 2019-02-12 09:39:31,042 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 09:39:31,052 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:31,052 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 09:39:31,061 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 09:39:31,141 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 09:39:31,144 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000000_0
   [druid] 2019-02-12 09:39:31,243 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:31,271 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:31,865 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@55784688
   [druid] 2019-02-12 09:39:31,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 09:39:32,021 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1058512454_0001 running in uber mode : false
   [druid] 2019-02-12 09:39:32,039 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 09:39:32,050 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:32,050 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:32,050 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:32,050 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:32,050 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:32,057 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:32,723 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:32,776 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000001_0
   [druid] 2019-02-12 09:39:32,777 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:32,777 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:32,869 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@d9c2aba
   [druid] 2019-02-12 09:39:32,874 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 09:39:32,960 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:32,960 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:32,960 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:32,960 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:32,961 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:32,962 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:32,976 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:32,999 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000002_0
   [druid] 2019-02-12 09:39:33,002 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:33,002 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:33,099 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@34bddcd1
   [druid] 2019-02-12 09:39:33,104 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 09:39:33,181 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:33,181 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:33,181 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:33,181 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:33,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:33,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:33,205 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:33,205 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:33,232 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:33,260 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:33,260 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000002_0' done.
   [druid] 2019-02-12 09:39:33,260 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000002_0
   [druid] 2019-02-12 09:39:33,261 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000003_0
   [druid] 2019-02-12 09:39:33,261 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:33,262 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:33,363 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f26cd44
   [druid] 2019-02-12 09:39:33,367 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 09:39:33,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:33,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:33,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:33,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:33,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:33,457 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:33,477 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:33,477 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:33,502 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:33,506 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:33,506 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000003_0' done.
   [druid] 2019-02-12 09:39:33,507 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000003_0
   [druid] 2019-02-12 09:39:33,507 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000004_0
   [druid] 2019-02-12 09:39:33,508 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:33,508 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:33,603 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@36f14039
   [druid] 2019-02-12 09:39:33,606 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 09:39:33,694 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:33,694 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:33,694 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:33,694 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:33,694 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:33,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:33,709 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:33,709 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:33,738 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:33,742 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:33,742 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000004_0' done.
   [druid] 2019-02-12 09:39:33,742 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000004_0
   [druid] 2019-02-12 09:39:33,742 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000005_0
   [druid] 2019-02-12 09:39:33,744 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:33,744 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:33,845 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5fe17a5d
   [druid] 2019-02-12 09:39:33,850 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 09:39:33,948 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:33,948 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:33,948 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:33,948 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:33,949 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:33,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:33,960 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:33,961 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:33,988 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:33,991 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:33,991 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000005_0' done.
   [druid] 2019-02-12 09:39:33,991 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000005_0
   [druid] 2019-02-12 09:39:33,991 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000006_0
   [druid] 2019-02-12 09:39:33,993 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:33,994 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:34,043 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 09:39:34,104 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3d3b1fba
   [druid] 2019-02-12 09:39:34,107 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 09:39:34,189 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:34,189 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:34,189 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:34,189 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:34,189 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:34,190 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:34,203 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:34,203 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:34,226 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:34,232 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:34,233 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000006_0' done.
   [druid] 2019-02-12 09:39:34,233 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000006_0
   [druid] 2019-02-12 09:39:34,233 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000007_0
   [druid] 2019-02-12 09:39:34,234 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:34,234 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:34,348 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@14517ffa
   [druid] 2019-02-12 09:39:34,353 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 09:39:34,437 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:34,437 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:34,438 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:34,438 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:34,438 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:34,440 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:34,457 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:34,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:34,481 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:34,483 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:34,483 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000007_0' done.
   [druid] 2019-02-12 09:39:34,484 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000007_0
   [druid] 2019-02-12 09:39:34,484 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000008_0
   [druid] 2019-02-12 09:39:34,485 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:34,485 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:34,583 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1a9f85c7
   [druid] 2019-02-12 09:39:34,588 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 09:39:34,674 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:34,674 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:34,674 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:34,674 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:34,675 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:34,676 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:34,686 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:34,686 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:34,708 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:34,710 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:34,711 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000008_0' done.
   [druid] 2019-02-12 09:39:34,711 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000008_0
   [druid] 2019-02-12 09:39:34,711 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1058512454_0001_m_000009_0
   [druid] 2019-02-12 09:39:34,714 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:39:34,714 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:39:34,835 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7bd31ea
   [druid] 2019-02-12 09:39:34,837 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 09:39:34,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:39:34,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:39:34,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:39:34,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:39:34,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:39:34,920 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:39:34,928 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:39:34,929 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:39:34,958 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1058512454_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:39:34,960 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:39:34,960 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1058512454_0001_m_000009_0' done.
   [druid] 2019-02-12 09:39:34,960 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1058512454_0001_m_000009_0
   [druid] 2019-02-12 09:39:34,962 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 09:39:34,962 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2019-02-12 09:39:34,964 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1058512454_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:347)
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)
	at com.phone.analysis.mr.model.base.KpiDimension.write(KpiDimension.java:83)
	at com.phone.analysis.mr.model.key.StatsCommonDimension.write(StatsCommonDimension.java:37)
	at com.phone.analysis.mr.model.key.StatsUserDimension.write(StatsUserDimension.java:77)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:60)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-02-12 09:39:35,053 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1058512454_0001 failed with state FAILED due to: NA
   [druid] 2019-02-12 09:39:35,109 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=48900
		FILE: Number of bytes written=2417928
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=222811
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=76
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=71
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=48
		Input split bytes=832
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=6259998720
	File Input Format Counters 
		Bytes Read=31932
   [druid] 2019-02-12 09:41:31,863 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 09:41:31,865 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 09:41:32,514 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 09:41:32,552 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 09:41:32,623 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 09:41:32,675 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 09:41:32,826 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1465429132_0001
   [druid] 2019-02-12 09:41:33,105 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 09:41:33,108 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1465429132_0001
   [druid] 2019-02-12 09:41:33,117 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 09:41:33,128 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:33,128 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 09:41:33,138 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 09:41:33,215 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 09:41:33,218 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000000_0
   [druid] 2019-02-12 09:41:33,244 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:33,249 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:33,360 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@8a5e46b
   [druid] 2019-02-12 09:41:33,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 09:41:33,449 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:33,449 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:33,449 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:33,449 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:33,449 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:33,454 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:33,903 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:33,934 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000001_0
   [druid] 2019-02-12 09:41:33,936 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:33,936 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:34,053 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@453a53af
   [druid] 2019-02-12 09:41:34,059 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 09:41:34,112 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1465429132_0001 running in uber mode : false
   [druid] 2019-02-12 09:41:34,116 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 09:41:34,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:34,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:34,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:34,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:34,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:34,118 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:34,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:34,206 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000002_0
   [druid] 2019-02-12 09:41:34,211 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:34,211 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:36,624 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7a8043f6
   [druid] 2019-02-12 09:41:36,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 09:41:36,682 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:36,682 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:36,682 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:36,682 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:36,682 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:36,683 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:36,700 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:36,700 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:36,717 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:36,733 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:36,733 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000002_0' done.
   [druid] 2019-02-12 09:41:36,733 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000002_0
   [druid] 2019-02-12 09:41:36,733 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000003_0
   [druid] 2019-02-12 09:41:36,734 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:36,735 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:36,827 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@648c1f92
   [druid] 2019-02-12 09:41:36,830 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 09:41:36,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:36,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:36,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:36,898 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:36,898 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:36,899 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:36,910 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:36,910 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:36,932 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:36,935 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:36,935 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000003_0' done.
   [druid] 2019-02-12 09:41:36,935 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000003_0
   [druid] 2019-02-12 09:41:36,935 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000004_0
   [druid] 2019-02-12 09:41:36,937 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:36,937 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:37,032 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@30747400
   [druid] 2019-02-12 09:41:37,037 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 09:41:37,116 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:37,116 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:37,116 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:37,116 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:37,116 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:37,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:37,119 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 09:41:37,130 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:37,130 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:37,153 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:37,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:37,157 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000004_0' done.
   [druid] 2019-02-12 09:41:37,157 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000004_0
   [druid] 2019-02-12 09:41:37,157 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000005_0
   [druid] 2019-02-12 09:41:37,158 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:37,158 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:37,258 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2bf3707a
   [druid] 2019-02-12 09:41:37,263 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 09:41:37,335 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:37,335 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:37,335 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:37,335 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:37,335 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:37,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:37,346 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:37,346 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:37,371 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:37,375 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:37,375 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000005_0' done.
   [druid] 2019-02-12 09:41:37,375 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000005_0
   [druid] 2019-02-12 09:41:37,375 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000006_0
   [druid] 2019-02-12 09:41:37,376 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:37,376 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:37,468 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1732eab6
   [druid] 2019-02-12 09:41:37,472 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 09:41:37,553 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:37,553 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:37,554 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:37,554 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:37,554 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:37,555 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:37,568 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:37,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:37,590 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:37,593 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:37,593 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000006_0' done.
   [druid] 2019-02-12 09:41:37,593 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000006_0
   [druid] 2019-02-12 09:41:37,593 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000007_0
   [druid] 2019-02-12 09:41:37,594 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:37,594 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:37,694 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1c436d6f
   [druid] 2019-02-12 09:41:37,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 09:41:37,767 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:37,767 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:37,767 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:37,767 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:37,767 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:37,768 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:37,779 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:37,779 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:37,807 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:37,809 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:37,809 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000007_0' done.
   [druid] 2019-02-12 09:41:37,809 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000007_0
   [druid] 2019-02-12 09:41:37,809 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000008_0
   [druid] 2019-02-12 09:41:37,811 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:37,811 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:37,915 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2354d44e
   [druid] 2019-02-12 09:41:37,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 09:41:37,994 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:37,994 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:37,994 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:37,994 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:37,994 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:37,995 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:38,014 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:38,014 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:38,037 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:38,040 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:38,041 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000008_0' done.
   [druid] 2019-02-12 09:41:38,041 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000008_0
   [druid] 2019-02-12 09:41:38,041 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1465429132_0001_m_000009_0
   [druid] 2019-02-12 09:41:38,042 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 09:41:38,042 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 09:41:38,144 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@493672d4
   [druid] 2019-02-12 09:41:38,147 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 09:41:38,229 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 09:41:38,229 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 09:41:38,229 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 09:41:38,229 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 09:41:38,229 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 09:41:38,230 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 09:41:38,239 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 09:41:38,239 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 09:41:38,267 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1465429132_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 09:41:38,269 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 09:41:38,269 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1465429132_0001_m_000009_0' done.
   [druid] 2019-02-12 09:41:38,269 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1465429132_0001_m_000009_0
   [druid] 2019-02-12 09:41:38,269 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 09:41:38,269 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2019-02-12 09:41:38,271 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1465429132_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:347)
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)
	at com.phone.analysis.mr.model.base.KpiDimension.write(KpiDimension.java:83)
	at com.phone.analysis.mr.model.key.StatsCommonDimension.write(StatsCommonDimension.java:37)
	at com.phone.analysis.mr.model.key.StatsUserDimension.write(StatsUserDimension.java:77)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:60)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-02-12 09:41:39,121 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1465429132_0001 failed with state FAILED due to: NA
   [druid] 2019-02-12 09:41:39,146 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=48900
		FILE: Number of bytes written=2417928
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=222811
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=76
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=71
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=48
		Input split bytes=832
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=6390022144
	File Input Format Counters 
		Bytes Read=31932
   [druid] 2019-02-12 09:41:39,245 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > sort
   [druid] 2019-02-12 14:23:57,965 [main           ] ERROR m.phone.etl.mr.EtlToHdfsRunner {1} - mysql
   java.lang.RuntimeException: /ods/02/11
	at com.phone.util.InAndOutPathUtil.handleInputOutput(InAndOutPathUtil.java:41)
	at com.phone.analysis.mr.nm.ActiveMemberRunner.run(ActiveMemberRunner.java:45)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.analysis.mr.nm.ActiveMemberRunner.main(ActiveMemberRunner.java:65)
[druid] 2019-02-12 14:24:34,161 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 14:24:34,163 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 14:24:34,903 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 14:24:34,985 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 14:24:35,091 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 14:24:35,259 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1587268879_0001
   [druid] 2019-02-12 14:24:35,480 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 14:24:35,481 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1587268879_0001
   [druid] 2019-02-12 14:24:35,484 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 14:24:35,496 [Thread-4       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:35,496 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 14:24:35,508 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 14:24:35,585 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 14:24:35,587 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000000_0
   [druid] 2019-02-12 14:24:35,611 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:35,622 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:35,842 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44da8150
   [druid] 2019-02-12 14:24:35,851 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 14:24:35,936 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:35,936 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:35,937 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:35,937 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:35,937 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:35,940 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:36,412 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:36,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:36,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:36,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 9611; bufvoid = 104857600
   [druid] 2019-02-12 14:24:36,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214064(104856256); length = 333/6553600
   [druid] 2019-02-12 14:24:36,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:36,471 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:36,484 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1587268879_0001 running in uber mode : false
   [druid] 2019-02-12 14:24:36,485 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:36,485 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000000_0' done.
   [druid] 2019-02-12 14:24:36,485 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000000_0
   [druid] 2019-02-12 14:24:36,485 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000001_0
   [druid] 2019-02-12 14:24:36,486 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 14:24:36,487 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:36,487 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:36,610 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f5a40b4
   [druid] 2019-02-12 14:24:36,614 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 14:24:36,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:36,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:36,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:36,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:36,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:36,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:36,720 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:36,721 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:36,721 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:36,721 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 2964; bufvoid = 104857600
   [druid] 2019-02-12 14:24:36,721 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600
   [druid] 2019-02-12 14:24:36,736 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:36,746 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:36,748 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:36,748 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000001_0' done.
   [druid] 2019-02-12 14:24:36,748 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000001_0
   [druid] 2019-02-12 14:24:36,748 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000002_0
   [druid] 2019-02-12 14:24:36,750 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:36,750 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:36,846 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@e32ee8d
   [druid] 2019-02-12 14:24:36,849 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 14:24:36,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:36,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:36,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:36,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:36,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:36,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:36,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:36,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:36,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:36,951 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1944; bufvoid = 104857600
   [druid] 2019-02-12 14:24:36,951 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
   [druid] 2019-02-12 14:24:36,963 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:36,974 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:36,978 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:36,978 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000002_0' done.
   [druid] 2019-02-12 14:24:36,978 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000002_0
   [druid] 2019-02-12 14:24:36,978 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000003_0
   [druid] 2019-02-12 14:24:36,979 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:36,979 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:37,083 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@482d98ba
   [druid] 2019-02-12 14:24:37,086 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 14:24:37,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:37,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:37,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:37,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:37,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:37,174 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:37,182 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:24:37,183 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:24:37,183 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:24:37,183 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:24:37,184 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:37,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:37,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:37,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 648; bufvoid = 104857600
   [druid] 2019-02-12 14:24:37,185 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
   [druid] 2019-02-12 14:24:37,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:37,208 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:37,211 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:37,211 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000003_0' done.
   [druid] 2019-02-12 14:24:37,211 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000003_0
   [druid] 2019-02-12 14:24:37,211 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000004_0
   [druid] 2019-02-12 14:24:37,212 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:37,213 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:37,308 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3d0503b9
   [druid] 2019-02-12 14:24:37,314 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 14:24:37,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:37,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:37,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:37,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:37,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:37,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:37,424 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:37,424 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:37,424 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:37,424 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 432; bufvoid = 104857600
   [druid] 2019-02-12 14:24:37,424 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2019-02-12 14:24:37,435 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:37,447 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:37,450 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:37,451 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000004_0' done.
   [druid] 2019-02-12 14:24:37,451 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000004_0
   [druid] 2019-02-12 14:24:37,451 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000005_0
   [druid] 2019-02-12 14:24:37,454 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:37,454 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:37,490 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 14:24:37,560 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b5a35c4
   [druid] 2019-02-12 14:24:37,565 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 14:24:37,655 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:37,655 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:37,656 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:37,656 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:37,656 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:37,658 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:37,668 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:37,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:37,688 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:37,690 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:37,690 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000005_0' done.
   [druid] 2019-02-12 14:24:37,690 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000005_0
   [druid] 2019-02-12 14:24:37,690 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000006_0
   [druid] 2019-02-12 14:24:37,691 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:37,691 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:37,790 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2631dd23
   [druid] 2019-02-12 14:24:37,793 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 14:24:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:37,890 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:37,899 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:37,900 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:37,919 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:37,921 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:37,922 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000006_0' done.
   [druid] 2019-02-12 14:24:37,922 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000006_0
   [druid] 2019-02-12 14:24:37,922 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000007_0
   [druid] 2019-02-12 14:24:37,923 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:37,923 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:38,032 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2ec4468c
   [druid] 2019-02-12 14:24:38,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 14:24:38,120 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:38,120 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:38,120 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:38,120 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:38,120 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:38,122 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:38,130 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:38,130 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:38,147 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:38,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:38,150 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000007_0' done.
   [druid] 2019-02-12 14:24:38,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000007_0
   [druid] 2019-02-12 14:24:38,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000008_0
   [druid] 2019-02-12 14:24:38,152 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:38,152 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:38,276 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3336eb9
   [druid] 2019-02-12 14:24:38,280 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 14:24:38,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:38,371 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:38,371 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:38,371 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:38,371 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:38,372 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:38,380 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:38,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:38,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:38,381 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 432; bufvoid = 104857600
   [druid] 2019-02-12 14:24:38,381 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2019-02-12 14:24:38,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:38,403 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:38,406 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:38,406 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000008_0' done.
   [druid] 2019-02-12 14:24:38,406 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000008_0
   [druid] 2019-02-12 14:24:38,406 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_m_000009_0
   [druid] 2019-02-12 14:24:38,408 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:38,408 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:38,594 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@22509093
   [druid] 2019-02-12 14:24:38,597 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 14:24:38,703 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:24:38,703 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:24:38,703 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:24:38,703 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:24:38,703 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:24:38,705 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:24:38,716 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:24:38,716 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:24:38,716 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:24:38,716 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 432; bufvoid = 104857600
   [druid] 2019-02-12 14:24:38,716 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2019-02-12 14:24:38,744 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:24:38,759 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:38,762 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:24:38,762 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_m_000009_0' done.
   [druid] 2019-02-12 14:24:38,762 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_m_000009_0
   [druid] 2019-02-12 14:24:38,762 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 14:24:38,781 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 14:24:38,783 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1587268879_0001_r_000000_0
   [druid] 2019-02-12 14:24:38,805 [pool-7-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:24:38,805 [pool-7-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:24:38,906 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@278f01bf
   [druid] 2019-02-12 14:24:38,913 [pool-7-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@199f0cad
   [druid] 2019-02-12 14:24:38,956 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 14:24:38,961 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1587268879_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 14:24:39,049 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000002_0 decomp: 1982 len: 1986 to MEMORY
   [druid] 2019-02-12 14:24:39,063 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1982 bytes from map-output for attempt_local1587268879_0001_m_000002_0
   [druid] 2019-02-12 14:24:39,066 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1982, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1982
   [druid] 2019-02-12 14:24:39,086 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000008_0 decomp: 442 len: 446 to MEMORY
   [druid] 2019-02-12 14:24:39,088 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 442 bytes from map-output for attempt_local1587268879_0001_m_000008_0
   [druid] 2019-02-12 14:24:39,089 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 442, inMemoryMapOutputs.size() -> 2, commitMemory -> 1982, usedMemory ->2424
   [druid] 2019-02-12 14:24:39,097 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 14:24:39,098 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1587268879_0001_m_000005_0
   [druid] 2019-02-12 14:24:39,098 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 2424, usedMemory ->2426
   [druid] 2019-02-12 14:24:39,105 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000004_0 decomp: 442 len: 446 to MEMORY
   [druid] 2019-02-12 14:24:39,106 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 442 bytes from map-output for attempt_local1587268879_0001_m_000004_0
   [druid] 2019-02-12 14:24:39,106 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 442, inMemoryMapOutputs.size() -> 4, commitMemory -> 2426, usedMemory ->2868
   [druid] 2019-02-12 14:24:39,114 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000001_0 decomp: 3010 len: 3014 to MEMORY
   [druid] 2019-02-12 14:24:39,116 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 3010 bytes from map-output for attempt_local1587268879_0001_m_000001_0
   [druid] 2019-02-12 14:24:39,116 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 3010, inMemoryMapOutputs.size() -> 5, commitMemory -> 2868, usedMemory ->5878
   [druid] 2019-02-12 14:24:39,124 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 14:24:39,125 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1587268879_0001_m_000007_0
   [druid] 2019-02-12 14:24:39,126 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 5878, usedMemory ->5880
   [druid] 2019-02-12 14:24:39,135 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000000_0 decomp: 9781 len: 9785 to MEMORY
   [druid] 2019-02-12 14:24:39,136 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 9781 bytes from map-output for attempt_local1587268879_0001_m_000000_0
   [druid] 2019-02-12 14:24:39,136 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 9781, inMemoryMapOutputs.size() -> 7, commitMemory -> 5880, usedMemory ->15661
   [druid] 2019-02-12 14:24:39,145 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 14:24:39,147 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1587268879_0001_m_000006_0
   [druid] 2019-02-12 14:24:39,147 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 15661, usedMemory ->15663
   [druid] 2019-02-12 14:24:39,154 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000003_0 decomp: 662 len: 666 to MEMORY
   [druid] 2019-02-12 14:24:39,156 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 662 bytes from map-output for attempt_local1587268879_0001_m_000003_0
   [druid] 2019-02-12 14:24:39,157 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 662, inMemoryMapOutputs.size() -> 9, commitMemory -> 15663, usedMemory ->16325
   [druid] 2019-02-12 14:24:39,165 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1587268879_0001_m_000009_0 decomp: 442 len: 446 to MEMORY
   [druid] 2019-02-12 14:24:39,166 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 442 bytes from map-output for attempt_local1587268879_0001_m_000009_0
   [druid] 2019-02-12 14:24:39,166 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 442, inMemoryMapOutputs.size() -> 10, commitMemory -> 16325, usedMemory ->16767
   [druid] 2019-02-12 14:24:39,167 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 14:24:39,168 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 14:24:39,168 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 14:24:39,190 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 14:24:39,192 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 7 segments left of total size: 16208 bytes
   [druid] 2019-02-12 14:24:39,201 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 16767 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 14:24:39,203 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 16753 bytes from disk
   [druid] 2019-02-12 14:24:39,205 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 14:24:39,206 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 14:24:39,207 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 16670 bytes
   [druid] 2019-02-12 14:24:39,208 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 14:24:40,016 [pool-7-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 14:24:40,088 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1587268879_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:24:40,091 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 14:24:40,092 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1587268879_0001_r_000000_0' done.
   [druid] 2019-02-12 14:24:40,092 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1587268879_0001_r_000000_0
   [druid] 2019-02-12 14:24:40,092 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 14:24:40,197 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 14:24:40,501 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 14:24:40,502 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1587268879_0001 completed successfully
   [druid] 2019-02-12 14:24:40,564 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=94502
		FILE: Number of bytes written=3448578
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=142
		Map output bytes=16463
		Map output materialized bytes=16807
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=13
		Reduce shuffle bytes=16807
		Reduce input records=142
		Reduce output records=13
		Spilled Records=284
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=8107589632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 14:28:27,337 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 14:28:27,339 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 14:28:28,157 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 14:28:28,255 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 14:28:28,317 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 14:28:28,472 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local770132444_0001
   [druid] 2019-02-12 14:28:28,689 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 14:28:28,691 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local770132444_0001
   [druid] 2019-02-12 14:28:28,692 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 14:28:28,699 [Thread-4       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:28,699 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 14:28:28,711 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 14:28:28,774 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 14:28:28,778 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000000_0
   [druid] 2019-02-12 14:28:28,816 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:28,827 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:28,958 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4ecdbab8
   [druid] 2019-02-12 14:28:28,972 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 14:28:29,061 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:29,061 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:29,061 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:29,061 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:29,061 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:29,065 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:29,495 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:29,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:29,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:29,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 9611; bufvoid = 104857600
   [druid] 2019-02-12 14:28:29,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214064(104856256); length = 333/6553600
   [druid] 2019-02-12 14:28:29,523 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:29,535 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:29,549 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:29,549 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000000_0' done.
   [druid] 2019-02-12 14:28:29,549 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000000_0
   [druid] 2019-02-12 14:28:29,549 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000001_0
   [druid] 2019-02-12 14:28:29,551 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:29,551 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:29,660 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2dfddfaa
   [druid] 2019-02-12 14:28:29,663 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 14:28:29,694 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local770132444_0001 running in uber mode : false
   [druid] 2019-02-12 14:28:29,695 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 14:28:29,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:29,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:29,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:29,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:29,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:29,727 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:29,747 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:29,748 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:29,748 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:29,748 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 2964; bufvoid = 104857600
   [druid] 2019-02-12 14:28:29,748 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600
   [druid] 2019-02-12 14:28:29,770 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:29,783 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:29,785 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:29,785 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000001_0' done.
   [druid] 2019-02-12 14:28:29,785 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000001_0
   [druid] 2019-02-12 14:28:29,785 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000002_0
   [druid] 2019-02-12 14:28:29,787 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:29,787 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:29,914 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@53ecc6f8
   [druid] 2019-02-12 14:28:29,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 14:28:29,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:29,987 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:29,987 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:29,987 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:29,987 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:29,987 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:29,998 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:29,998 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:29,998 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:29,998 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1944; bufvoid = 104857600
   [druid] 2019-02-12 14:28:29,998 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
   [druid] 2019-02-12 14:28:30,011 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:30,021 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:30,025 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:30,025 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000002_0' done.
   [druid] 2019-02-12 14:28:30,026 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000002_0
   [druid] 2019-02-12 14:28:30,028 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000003_0
   [druid] 2019-02-12 14:28:30,030 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:30,030 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:30,134 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@284e21c5
   [druid] 2019-02-12 14:28:30,138 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 14:28:30,209 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:30,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:30,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:30,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:30,210 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:30,211 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:30,218 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:28:30,218 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:28:30,218 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:28:30,218 [ask Executor #0] INFO  lysis.mr.nm.ActiveMemberMapper {1} - serverTimeuuid
   [druid] 2019-02-12 14:28:30,219 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:30,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:30,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:30,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 648; bufvoid = 104857600
   [druid] 2019-02-12 14:28:30,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
   [druid] 2019-02-12 14:28:30,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:30,245 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:30,247 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:30,247 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000003_0' done.
   [druid] 2019-02-12 14:28:30,247 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000003_0
   [druid] 2019-02-12 14:28:30,248 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000004_0
   [druid] 2019-02-12 14:28:30,249 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:30,249 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:30,384 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6d313de5
   [druid] 2019-02-12 14:28:30,386 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 14:28:30,452 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:30,452 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:30,452 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:30,452 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:30,452 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:30,453 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:30,471 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:30,471 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:30,471 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:30,471 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 432; bufvoid = 104857600
   [druid] 2019-02-12 14:28:30,471 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2019-02-12 14:28:30,486 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:30,499 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:30,502 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:30,502 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000004_0' done.
   [druid] 2019-02-12 14:28:30,502 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000004_0
   [druid] 2019-02-12 14:28:30,502 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000005_0
   [druid] 2019-02-12 14:28:30,504 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:30,504 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:30,610 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@661fe4c8
   [druid] 2019-02-12 14:28:30,616 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 14:28:30,687 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:30,687 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:30,687 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:30,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:30,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:30,691 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:30,701 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:30,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:30,724 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:30,726 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:30,726 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000005_0' done.
   [druid] 2019-02-12 14:28:30,726 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000005_0
   [druid] 2019-02-12 14:28:30,727 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000006_0
   [druid] 2019-02-12 14:28:30,728 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:30,729 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:30,839 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@27c1b9d6
   [druid] 2019-02-12 14:28:30,843 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 14:28:30,913 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:30,913 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:30,913 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:30,913 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:30,914 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:30,921 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:30,935 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:30,935 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:30,958 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:30,961 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:30,962 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000006_0' done.
   [druid] 2019-02-12 14:28:30,962 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000006_0
   [druid] 2019-02-12 14:28:30,962 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000007_0
   [druid] 2019-02-12 14:28:30,963 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:30,963 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:31,070 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7f85dbae
   [druid] 2019-02-12 14:28:31,075 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 14:28:31,135 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:31,135 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:31,135 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:31,135 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:31,135 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:31,137 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:31,154 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:31,154 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:31,181 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:31,185 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:31,185 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000007_0' done.
   [druid] 2019-02-12 14:28:31,185 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000007_0
   [druid] 2019-02-12 14:28:31,185 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000008_0
   [druid] 2019-02-12 14:28:31,187 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:31,187 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:31,304 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@73691dd1
   [druid] 2019-02-12 14:28:31,309 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 14:28:31,378 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:31,378 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:31,378 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:31,378 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:31,378 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:31,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:31,387 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:31,387 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:31,387 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:31,387 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 432; bufvoid = 104857600
   [druid] 2019-02-12 14:28:31,387 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2019-02-12 14:28:31,402 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:31,411 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:31,413 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:31,414 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000008_0' done.
   [druid] 2019-02-12 14:28:31,414 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000008_0
   [druid] 2019-02-12 14:28:31,414 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_m_000009_0
   [druid] 2019-02-12 14:28:31,415 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:31,415 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:31,522 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56620855
   [druid] 2019-02-12 14:28:31,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 14:28:31,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 14:28:31,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 14:28:31,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 14:28:31,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 14:28:31,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 14:28:31,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 14:28:31,633 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 14:28:31,634 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 14:28:31,634 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 14:28:31,634 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 432; bufvoid = 104857600
   [druid] 2019-02-12 14:28:31,634 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2019-02-12 14:28:31,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 14:28:31,654 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:31,657 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 14:28:31,658 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_m_000009_0' done.
   [druid] 2019-02-12 14:28:31,658 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_m_000009_0
   [druid] 2019-02-12 14:28:31,658 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 14:28:31,661 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 14:28:31,662 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local770132444_0001_r_000000_0
   [druid] 2019-02-12 14:28:31,679 [pool-7-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 14:28:31,679 [pool-7-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 14:28:31,788 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@38ed3f7a
   [druid] 2019-02-12 14:28:31,794 [pool-7-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2fe815c0
   [druid] 2019-02-12 14:28:31,808 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 14:28:31,810 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local770132444_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 14:28:31,890 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000003_0 decomp: 662 len: 666 to MEMORY
   [druid] 2019-02-12 14:28:31,897 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 662 bytes from map-output for attempt_local770132444_0001_m_000003_0
   [druid] 2019-02-12 14:28:31,901 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 662, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->662
   [druid] 2019-02-12 14:28:31,914 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000000_0 decomp: 9781 len: 9785 to MEMORY
   [druid] 2019-02-12 14:28:31,917 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 9781 bytes from map-output for attempt_local770132444_0001_m_000000_0
   [druid] 2019-02-12 14:28:31,917 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 9781, inMemoryMapOutputs.size() -> 2, commitMemory -> 662, usedMemory ->10443
   [druid] 2019-02-12 14:28:31,931 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000001_0 decomp: 3010 len: 3014 to MEMORY
   [druid] 2019-02-12 14:28:31,934 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 3010 bytes from map-output for attempt_local770132444_0001_m_000001_0
   [druid] 2019-02-12 14:28:31,935 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 3010, inMemoryMapOutputs.size() -> 3, commitMemory -> 10443, usedMemory ->13453
   [druid] 2019-02-12 14:28:31,944 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 14:28:31,946 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local770132444_0001_m_000007_0
   [druid] 2019-02-12 14:28:31,946 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 13453, usedMemory ->13455
   [druid] 2019-02-12 14:28:31,957 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000004_0 decomp: 442 len: 446 to MEMORY
   [druid] 2019-02-12 14:28:31,959 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 442 bytes from map-output for attempt_local770132444_0001_m_000004_0
   [druid] 2019-02-12 14:28:31,959 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 442, inMemoryMapOutputs.size() -> 5, commitMemory -> 13455, usedMemory ->13897
   [druid] 2019-02-12 14:28:31,965 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 14:28:31,967 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local770132444_0001_m_000005_0
   [druid] 2019-02-12 14:28:31,967 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 13897, usedMemory ->13899
   [druid] 2019-02-12 14:28:31,973 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000002_0 decomp: 1982 len: 1986 to MEMORY
   [druid] 2019-02-12 14:28:31,974 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1982 bytes from map-output for attempt_local770132444_0001_m_000002_0
   [druid] 2019-02-12 14:28:31,974 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1982, inMemoryMapOutputs.size() -> 7, commitMemory -> 13899, usedMemory ->15881
   [druid] 2019-02-12 14:28:31,979 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000008_0 decomp: 442 len: 446 to MEMORY
   [druid] 2019-02-12 14:28:31,980 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 442 bytes from map-output for attempt_local770132444_0001_m_000008_0
   [druid] 2019-02-12 14:28:31,980 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 442, inMemoryMapOutputs.size() -> 8, commitMemory -> 15881, usedMemory ->16323
   [druid] 2019-02-12 14:28:31,985 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000009_0 decomp: 442 len: 446 to MEMORY
   [druid] 2019-02-12 14:28:31,987 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 442 bytes from map-output for attempt_local770132444_0001_m_000009_0
   [druid] 2019-02-12 14:28:31,987 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 442, inMemoryMapOutputs.size() -> 9, commitMemory -> 16323, usedMemory ->16765
   [druid] 2019-02-12 14:28:31,993 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local770132444_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 14:28:31,994 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local770132444_0001_m_000006_0
   [druid] 2019-02-12 14:28:31,994 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 16765, usedMemory ->16767
   [druid] 2019-02-12 14:28:31,994 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 14:28:31,995 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 14:28:31,995 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 14:28:32,019 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 14:28:32,020 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 7 segments left of total size: 16208 bytes
   [druid] 2019-02-12 14:28:32,026 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 16767 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 14:28:32,028 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 16753 bytes from disk
   [druid] 2019-02-12 14:28:32,029 [pool-7-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 14:28:32,029 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 14:28:32,029 [pool-7-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 16670 bytes
   [druid] 2019-02-12 14:28:32,030 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 14:28:32,433 [pool-7-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 14:28:32,477 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local770132444_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 14:28:32,479 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 14:28:32,479 [pool-7-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local770132444_0001_r_000000_0' done.
   [druid] 2019-02-12 14:28:32,479 [pool-7-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local770132444_0001_r_000000_0
   [druid] 2019-02-12 14:28:32,479 [Thread-4       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 14:28:32,595 [Thread-4       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 14:28:32,700 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 14:28:32,701 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local770132444_0001 completed successfully
   [druid] 2019-02-12 14:28:32,777 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=94502
		FILE: Number of bytes written=3431726
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=142
		Map output bytes=16463
		Map output materialized bytes=16807
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=13
		Reduce shuffle bytes=16807
		Reduce input records=142
		Reduce output records=13
		Spilled Records=284
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=8101822464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 20:38:29,259 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:38:29,290 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:38:30,041 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:38:30,118 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:38:30,220 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:38:30,302 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:38:30,476 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local53807353_0001
   [druid] 2019-02-12 20:38:30,727 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:38:30,728 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local53807353_0001
   [druid] 2019-02-12 20:38:30,734 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:38:30,745 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:30,745 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:38:30,755 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:38:30,826 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:38:30,832 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000000_0
   [druid] 2019-02-12 20:38:30,872 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:30,878 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:31,126 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7a69b43e
   [druid] 2019-02-12 20:38:31,139 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:38:31,231 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:31,232 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:31,232 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:31,232 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:31,232 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:31,237 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:31,733 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local53807353_0001 running in uber mode : false
   [druid] 2019-02-12 20:38:31,734 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 20:38:31,749 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:31,787 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000001_0
   [druid] 2019-02-12 20:38:31,788 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:31,788 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:31,889 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@57908f44
   [druid] 2019-02-12 20:38:31,892 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:38:31,962 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:31,963 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:31,963 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:31,963 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:31,963 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:31,964 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:31,976 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:32,004 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000002_0
   [druid] 2019-02-12 20:38:32,006 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:32,006 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:32,127 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25de80e7
   [druid] 2019-02-12 20:38:32,131 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:38:32,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:32,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:32,213 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:32,213 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:32,213 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:32,213 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:32,229 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:32,230 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:32,252 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:32,268 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:32,269 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000002_0' done.
   [druid] 2019-02-12 20:38:32,269 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000002_0
   [druid] 2019-02-12 20:38:32,269 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000003_0
   [druid] 2019-02-12 20:38:32,271 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:32,272 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:32,383 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16ffffd4
   [druid] 2019-02-12 20:38:32,385 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:38:32,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:32,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:32,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:32,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:32,465 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:32,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:32,476 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:32,476 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:32,500 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:32,505 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:32,505 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000003_0' done.
   [druid] 2019-02-12 20:38:32,505 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000003_0
   [druid] 2019-02-12 20:38:32,505 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000004_0
   [druid] 2019-02-12 20:38:32,507 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:32,507 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:32,616 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2a2d84f4
   [druid] 2019-02-12 20:38:32,619 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:38:32,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:32,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:32,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:32,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:32,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:32,697 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:32,707 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:32,707 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:32,733 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:32,736 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:32,736 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000004_0' done.
   [druid] 2019-02-12 20:38:32,736 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000004_0
   [druid] 2019-02-12 20:38:32,737 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000005_0
   [druid] 2019-02-12 20:38:32,737 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:38:32,738 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:32,738 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:32,853 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7d09e94b
   [druid] 2019-02-12 20:38:32,861 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:38:32,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:32,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:32,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:32,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:32,941 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:32,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:32,952 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:32,952 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:32,976 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:32,978 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:32,978 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000005_0' done.
   [druid] 2019-02-12 20:38:32,979 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000005_0
   [druid] 2019-02-12 20:38:32,979 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000006_0
   [druid] 2019-02-12 20:38:32,980 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:32,980 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:33,087 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7deb98f6
   [druid] 2019-02-12 20:38:33,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:38:33,169 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:33,169 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:33,169 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:33,170 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:33,170 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:33,171 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:33,180 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:33,181 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:33,203 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:33,207 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:33,207 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000006_0' done.
   [druid] 2019-02-12 20:38:33,208 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000006_0
   [druid] 2019-02-12 20:38:33,208 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000007_0
   [druid] 2019-02-12 20:38:33,209 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:33,209 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:33,321 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@70666816
   [druid] 2019-02-12 20:38:33,324 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:38:33,394 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:33,394 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:33,394 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:33,394 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:33,394 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:33,396 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:33,406 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:33,406 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:33,429 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:33,431 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:33,432 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000007_0' done.
   [druid] 2019-02-12 20:38:33,432 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000007_0
   [druid] 2019-02-12 20:38:33,432 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000008_0
   [druid] 2019-02-12 20:38:33,433 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:33,433 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:33,568 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5fd811d8
   [druid] 2019-02-12 20:38:33,571 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:38:33,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:33,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:33,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:33,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:33,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:33,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:33,682 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:33,682 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:33,706 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:33,712 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:33,712 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000008_0' done.
   [druid] 2019-02-12 20:38:33,712 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000008_0
   [druid] 2019-02-12 20:38:33,712 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local53807353_0001_m_000009_0
   [druid] 2019-02-12 20:38:33,713 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:38:33,714 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:38:33,826 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4a1690ac
   [druid] 2019-02-12 20:38:33,829 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:38:33,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:38:33,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:38:33,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:38:33,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:38:33,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:38:33,912 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:38:33,921 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:38:33,921 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:38:33,947 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local53807353_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:38:33,949 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:38:33,950 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local53807353_0001_m_000009_0' done.
   [druid] 2019-02-12 20:38:33,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local53807353_0001_m_000009_0
   [druid] 2019-02-12 20:38:33,950 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:38:33,950 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2019-02-12 20:38:33,952 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local53807353_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:347)
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)
	at com.phone.analysis.mr.model.base.KpiDimension.write(KpiDimension.java:83)
	at com.phone.analysis.mr.model.key.StatsCommonDimension.write(StatsCommonDimension.java:37)
	at com.phone.analysis.mr.model.key.StatsUserDimension.write(StatsUserDimension.java:77)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:60)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-02-12 20:38:34,738 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local53807353_0001 failed with state FAILED due to: NA
   [druid] 2019-02-12 20:38:34,835 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=48900
		FILE: Number of bytes written=2393192
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=222811
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=76
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=71
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=48
		Input split bytes=832
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=6390022144
	File Input Format Counters 
		Bytes Read=31932
   [druid] 2019-02-12 20:44:50,033 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:44:50,035 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:44:50,807 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:44:50,854 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:44:50,955 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:44:51,036 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:44:51,224 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local574248386_0001
   [druid] 2019-02-12 20:44:51,460 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:44:51,462 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local574248386_0001
   [druid] 2019-02-12 20:44:51,476 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:44:51,485 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:51,485 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:44:51,497 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:44:51,564 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:44:51,566 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000000_0
   [druid] 2019-02-12 20:44:51,611 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:51,618 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:51,748 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6ac21f03
   [druid] 2019-02-12 20:44:51,760 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:44:51,854 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:51,854 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:51,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:51,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:51,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:51,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:52,308 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:52,337 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000001_0
   [druid] 2019-02-12 20:44:52,338 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:52,338 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:52,439 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3683be0e
   [druid] 2019-02-12 20:44:52,442 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:44:52,469 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local574248386_0001 running in uber mode : false
   [druid] 2019-02-12 20:44:52,472 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 20:44:52,501 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:52,501 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:52,501 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:52,501 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:52,501 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:52,503 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:52,518 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:52,542 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000002_0
   [druid] 2019-02-12 20:44:52,545 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:52,545 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:52,659 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@41b2918d
   [druid] 2019-02-12 20:44:52,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:44:52,719 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:52,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:52,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:52,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:52,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:52,722 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:52,735 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:52,736 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:52,758 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:52,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:52,773 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000002_0' done.
   [druid] 2019-02-12 20:44:52,774 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000002_0
   [druid] 2019-02-12 20:44:52,774 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000003_0
   [druid] 2019-02-12 20:44:52,775 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:52,775 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:52,885 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@60347586
   [druid] 2019-02-12 20:44:52,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:44:52,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:52,951 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:52,951 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:52,951 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:52,951 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:52,952 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:52,960 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:52,960 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:52,986 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:52,989 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:52,989 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000003_0' done.
   [druid] 2019-02-12 20:44:52,990 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000003_0
   [druid] 2019-02-12 20:44:52,990 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000004_0
   [druid] 2019-02-12 20:44:52,991 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:52,991 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:53,121 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@699a7b44
   [druid] 2019-02-12 20:44:53,124 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:44:53,196 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:53,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:53,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:53,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:53,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:53,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:53,213 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:53,213 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:53,244 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:53,246 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:53,247 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000004_0' done.
   [druid] 2019-02-12 20:44:53,247 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000004_0
   [druid] 2019-02-12 20:44:53,247 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000005_0
   [druid] 2019-02-12 20:44:53,248 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:53,249 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:53,361 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1bee7499
   [druid] 2019-02-12 20:44:53,366 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:44:53,430 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:53,430 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:53,430 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:53,430 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:53,430 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:53,431 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:53,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:53,440 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:53,459 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:53,461 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:53,462 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000005_0' done.
   [druid] 2019-02-12 20:44:53,462 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000005_0
   [druid] 2019-02-12 20:44:53,462 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000006_0
   [druid] 2019-02-12 20:44:53,463 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:53,463 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:53,476 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:44:53,577 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@84525a
   [druid] 2019-02-12 20:44:53,580 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:44:53,646 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:53,646 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:53,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:53,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:53,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:53,648 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:53,659 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:53,659 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:53,679 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:53,681 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:53,681 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000006_0' done.
   [druid] 2019-02-12 20:44:53,681 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000006_0
   [druid] 2019-02-12 20:44:53,681 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000007_0
   [druid] 2019-02-12 20:44:53,683 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:53,683 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:53,796 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@240b90e8
   [druid] 2019-02-12 20:44:53,798 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:44:53,857 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:53,857 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:53,857 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:53,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:53,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:53,860 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:53,867 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:53,867 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:53,890 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:53,893 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:53,893 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000007_0' done.
   [druid] 2019-02-12 20:44:53,893 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000007_0
   [druid] 2019-02-12 20:44:53,893 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000008_0
   [druid] 2019-02-12 20:44:53,895 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:53,895 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:54,027 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a7edad9
   [druid] 2019-02-12 20:44:54,030 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:44:54,100 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:54,100 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:54,100 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:54,100 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:54,100 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:54,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:54,112 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:54,112 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:54,134 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:54,138 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:54,138 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000008_0' done.
   [druid] 2019-02-12 20:44:54,138 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000008_0
   [druid] 2019-02-12 20:44:54,138 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local574248386_0001_m_000009_0
   [druid] 2019-02-12 20:44:54,140 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:44:54,140 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:44:54,256 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1c5f6fb
   [druid] 2019-02-12 20:44:54,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:44:54,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:44:54,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:44:54,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:44:54,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:44:54,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:44:54,286 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:44:54,293 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:44:54,293 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:44:54,315 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local574248386_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:44:54,318 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:44:54,318 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local574248386_0001_m_000009_0' done.
   [druid] 2019-02-12 20:44:54,318 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local574248386_0001_m_000009_0
   [druid] 2019-02-12 20:44:54,318 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:44:54,319 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2019-02-12 20:44:54,320 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local574248386_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:347)
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)
	at com.phone.analysis.mr.model.base.KpiDimension.write(KpiDimension.java:83)
	at com.phone.analysis.mr.model.key.StatsCommonDimension.write(StatsCommonDimension.java:37)
	at com.phone.analysis.mr.model.key.StatsUserDimension.write(StatsUserDimension.java:77)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:60)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-02-12 20:44:54,477 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local574248386_0001 failed with state FAILED due to: NA
   [druid] 2019-02-12 20:44:54,504 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=48900
		FILE: Number of bytes written=2405560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=222811
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=76
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=71
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=48
		Input split bytes=832
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=6439305216
	File Input Format Counters 
		Bytes Read=31932
   [druid] 2019-02-12 20:46:10,968 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:46:10,970 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:46:11,739 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:46:11,786 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:46:11,888 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:46:11,957 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:46:12,110 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1277763928_0001
   [druid] 2019-02-12 20:46:12,359 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:46:12,361 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1277763928_0001
   [druid] 2019-02-12 20:46:12,364 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:46:12,374 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:12,375 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:46:12,386 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:46:12,460 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:46:12,465 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000000_0
   [druid] 2019-02-12 20:46:12,502 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:12,509 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:12,636 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3efad939
   [druid] 2019-02-12 20:46:12,647 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:46:12,741 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:12,741 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:12,741 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:12,741 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:12,741 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:12,746 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:13,364 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1277763928_0001 running in uber mode : false
   [druid] 2019-02-12 20:46:13,365 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 20:46:13,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:13,418 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000001_0
   [druid] 2019-02-12 20:46:13,419 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:13,420 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:13,520 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5dcf527d
   [druid] 2019-02-12 20:46:13,523 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:46:13,586 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:13,586 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:13,586 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:13,586 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:13,586 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:13,587 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:13,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:13,630 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000002_0
   [druid] 2019-02-12 20:46:13,632 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:13,632 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:13,741 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6c2278f1
   [druid] 2019-02-12 20:46:13,744 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:46:13,806 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:13,806 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:13,806 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:13,807 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:13,807 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:13,807 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:13,820 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:13,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:13,843 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:13,857 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:13,857 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000002_0' done.
   [druid] 2019-02-12 20:46:13,858 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000002_0
   [druid] 2019-02-12 20:46:13,858 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000003_0
   [druid] 2019-02-12 20:46:13,859 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:13,859 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:13,972 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@8d5fa0b
   [druid] 2019-02-12 20:46:13,975 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:46:14,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:14,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:14,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:14,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:14,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:14,049 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:14,061 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:14,061 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:14,084 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:14,086 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:14,087 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000003_0' done.
   [druid] 2019-02-12 20:46:14,087 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000003_0
   [druid] 2019-02-12 20:46:14,087 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000004_0
   [druid] 2019-02-12 20:46:14,088 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:14,088 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:14,198 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46247bcb
   [druid] 2019-02-12 20:46:14,203 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:46:14,269 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:14,269 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:14,269 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:14,269 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:14,270 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:14,271 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:14,280 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:14,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:14,303 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:14,305 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:14,305 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000004_0' done.
   [druid] 2019-02-12 20:46:14,305 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000004_0
   [druid] 2019-02-12 20:46:14,305 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000005_0
   [druid] 2019-02-12 20:46:14,307 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:14,307 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:14,369 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:46:14,412 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@55331fd1
   [druid] 2019-02-12 20:46:14,416 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:46:14,478 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:14,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:14,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:14,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:14,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:14,480 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:14,491 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:14,491 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:14,521 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:14,524 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:14,524 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000005_0' done.
   [druid] 2019-02-12 20:46:14,524 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000005_0
   [druid] 2019-02-12 20:46:14,524 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000006_0
   [druid] 2019-02-12 20:46:14,526 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:14,526 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:14,703 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@54ddd7df
   [druid] 2019-02-12 20:46:14,706 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:46:14,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:14,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:14,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:14,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:14,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:14,774 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:14,782 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:14,782 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:14,802 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:14,804 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:14,804 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000006_0' done.
   [druid] 2019-02-12 20:46:14,804 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000006_0
   [druid] 2019-02-12 20:46:14,804 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000007_0
   [druid] 2019-02-12 20:46:14,806 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:14,806 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:14,907 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d03265e
   [druid] 2019-02-12 20:46:14,910 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:46:14,979 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:14,979 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:14,979 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:14,979 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:14,979 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:14,981 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:14,990 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:14,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:15,009 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:15,012 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:15,013 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000007_0' done.
   [druid] 2019-02-12 20:46:15,013 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000007_0
   [druid] 2019-02-12 20:46:15,013 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000008_0
   [druid] 2019-02-12 20:46:15,014 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:15,014 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:15,120 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2fb64359
   [druid] 2019-02-12 20:46:15,123 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:46:15,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:15,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:15,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:15,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:15,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:15,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:15,191 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:15,191 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:15,210 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:15,214 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:15,214 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000008_0' done.
   [druid] 2019-02-12 20:46:15,214 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000008_0
   [druid] 2019-02-12 20:46:15,214 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1277763928_0001_m_000009_0
   [druid] 2019-02-12 20:46:15,216 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:46:15,216 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:46:15,330 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25be3db4
   [druid] 2019-02-12 20:46:15,333 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:46:15,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:46:15,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:46:15,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:46:15,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:46:15,365 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:46:15,366 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:46:15,374 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:46:15,374 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:46:15,392 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1277763928_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:46:15,394 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:46:15,394 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1277763928_0001_m_000009_0' done.
   [druid] 2019-02-12 20:46:15,395 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1277763928_0001_m_000009_0
   [druid] 2019-02-12 20:46:15,395 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:46:15,395 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2019-02-12 20:46:15,397 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1277763928_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:347)
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)
	at com.phone.analysis.mr.model.base.KpiDimension.write(KpiDimension.java:83)
	at com.phone.analysis.mr.model.key.StatsCommonDimension.write(StatsCommonDimension.java:44)
	at com.phone.analysis.mr.model.key.StatsUserDimension.write(StatsUserDimension.java:83)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:60)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-02-12 20:46:16,369 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1277763928_0001 failed with state FAILED due to: NA
   [druid] 2019-02-12 20:46:16,396 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=48900
		FILE: Number of bytes written=2417928
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=222811
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=76
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=71
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=48
		Input split bytes=832
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=6427246592
	File Input Format Counters 
		Bytes Read=31932
   [druid] 2019-02-12 20:47:14,938 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:47:14,941 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:47:15,851 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:47:15,945 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:47:16,104 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:47:16,191 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:47:16,376 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local128041451_0001
   [druid] 2019-02-12 20:47:16,721 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:47:16,722 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local128041451_0001
   [druid] 2019-02-12 20:47:16,757 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:47:16,768 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:16,768 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:47:16,778 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:47:16,849 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:47:16,851 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000000_0
   [druid] 2019-02-12 20:47:16,896 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:16,906 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:17,064 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3efad939
   [druid] 2019-02-12 20:47:17,075 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:47:17,183 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:17,183 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:17,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:17,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:17,184 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:17,196 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:17,729 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local128041451_0001 running in uber mode : false
   [druid] 2019-02-12 20:47:17,731 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 20:47:17,905 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:17,963 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000001_0
   [druid] 2019-02-12 20:47:17,965 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:17,965 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:18,127 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5dcf527d
   [druid] 2019-02-12 20:47:18,131 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:47:18,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:18,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:18,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:18,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:18,197 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:18,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:18,207 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:18,227 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000002_0
   [druid] 2019-02-12 20:47:18,229 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:18,229 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:18,339 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@42756671
   [druid] 2019-02-12 20:47:18,341 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:47:18,402 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:18,402 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:18,403 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:18,403 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:18,403 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:18,404 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:18,415 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:18,416 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:18,447 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:18,462 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:18,462 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000002_0' done.
   [druid] 2019-02-12 20:47:18,462 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000002_0
   [druid] 2019-02-12 20:47:18,463 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000003_0
   [druid] 2019-02-12 20:47:18,465 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:18,465 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:18,572 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6106d4a6
   [druid] 2019-02-12 20:47:18,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:47:18,637 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:18,637 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:18,637 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:18,637 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:18,637 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:18,638 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:18,651 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:18,651 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:18,671 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:18,674 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:18,674 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000003_0' done.
   [druid] 2019-02-12 20:47:18,674 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000003_0
   [druid] 2019-02-12 20:47:18,674 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000004_0
   [druid] 2019-02-12 20:47:18,675 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:18,675 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:18,736 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:47:18,788 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2b314215
   [druid] 2019-02-12 20:47:18,791 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:47:18,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:18,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:18,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:18,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:18,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:18,856 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:18,873 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:18,873 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:18,895 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:18,897 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:18,897 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000004_0' done.
   [druid] 2019-02-12 20:47:18,897 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000004_0
   [druid] 2019-02-12 20:47:18,897 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000005_0
   [druid] 2019-02-12 20:47:18,898 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:18,899 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:19,010 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6af148e8
   [druid] 2019-02-12 20:47:19,015 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:47:19,078 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:19,078 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:19,078 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:19,078 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:19,079 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:19,080 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:19,092 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:19,092 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:19,116 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:19,118 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:19,118 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000005_0' done.
   [druid] 2019-02-12 20:47:19,118 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000005_0
   [druid] 2019-02-12 20:47:19,118 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000006_0
   [druid] 2019-02-12 20:47:19,120 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:19,120 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:19,231 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d03265e
   [druid] 2019-02-12 20:47:19,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:47:19,295 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:19,295 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:19,295 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:19,295 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:19,295 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:19,296 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:19,314 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:19,314 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:19,338 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:19,341 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:19,341 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000006_0' done.
   [druid] 2019-02-12 20:47:19,342 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000006_0
   [druid] 2019-02-12 20:47:19,342 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000007_0
   [druid] 2019-02-12 20:47:19,346 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:19,346 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:19,458 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2fb64359
   [druid] 2019-02-12 20:47:19,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:47:19,524 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:19,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:19,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:19,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:19,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:19,526 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:19,547 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:19,547 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:19,569 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:19,575 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:19,576 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000007_0' done.
   [druid] 2019-02-12 20:47:19,576 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000007_0
   [druid] 2019-02-12 20:47:19,576 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000008_0
   [druid] 2019-02-12 20:47:19,578 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:19,578 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:19,731 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6f5535a0
   [druid] 2019-02-12 20:47:19,734 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:47:19,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:19,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:19,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:19,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:19,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:19,838 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:19,848 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:19,848 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:19,890 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:19,894 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:19,895 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000008_0' done.
   [druid] 2019-02-12 20:47:19,895 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000008_0
   [druid] 2019-02-12 20:47:19,895 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local128041451_0001_m_000009_0
   [druid] 2019-02-12 20:47:19,896 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:47:19,896 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:47:20,082 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@255cda22
   [druid] 2019-02-12 20:47:20,086 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:47:20,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:47:20,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:47:20,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:47:20,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:47:20,127 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:47:20,128 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:47:20,138 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:47:20,138 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:47:20,160 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local128041451_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:47:20,164 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:47:20,165 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local128041451_0001_m_000009_0' done.
   [druid] 2019-02-12 20:47:20,165 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local128041451_0001_m_000009_0
   [druid] 2019-02-12 20:47:20,165 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:47:20,165 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2019-02-12 20:47:20,166 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local128041451_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:347)
	at java.io.DataOutputStream.writeUTF(DataOutputStream.java:323)
	at com.phone.analysis.mr.model.base.KpiDimension.write(KpiDimension.java:84)
	at com.phone.analysis.mr.model.key.StatsCommonDimension.write(StatsCommonDimension.java:44)
	at com.phone.analysis.mr.model.key.StatsUserDimension.write(StatsUserDimension.java:83)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:98)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:82)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1149)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:60)
	at com.phone.analysis.mr.nu.NewUserMapper.map(NewUserMapper.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-02-12 20:47:20,809 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local128041451_0001 failed with state FAILED due to: NA
   [druid] 2019-02-12 20:47:20,840 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=48900
		FILE: Number of bytes written=2405560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=222811
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=76
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=71
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=48
		Input split bytes=832
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=6424625152
	File Input Format Counters 
		Bytes Read=31932
   [druid] 2019-02-12 20:49:24,932 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:49:24,934 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:49:25,745 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:49:25,797 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:49:25,871 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:49:25,923 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:49:26,076 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1752576265_0001
   [druid] 2019-02-12 20:49:26,352 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:49:26,354 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1752576265_0001
   [druid] 2019-02-12 20:49:26,359 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:49:26,367 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:26,368 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:49:26,378 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:49:26,449 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:49:26,453 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000000_0
   [druid] 2019-02-12 20:49:26,493 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:26,500 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:26,631 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@79d4293e
   [druid] 2019-02-12 20:49:26,643 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:49:26,729 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:26,729 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:26,729 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:26,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:26,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:26,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:27,197 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:27,201 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:27,201 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 20:49:27,201 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1545; bufvoid = 104857600
   [druid] 2019-02-12 20:49:27,201 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
   [druid] 2019-02-12 20:49:27,240 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 20:49:27,252 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:27,267 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:27,267 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000000_0' done.
   [druid] 2019-02-12 20:49:27,267 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000000_0
   [druid] 2019-02-12 20:49:27,267 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000001_0
   [druid] 2019-02-12 20:49:27,269 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:27,269 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:27,357 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1752576265_0001 running in uber mode : false
   [druid] 2019-02-12 20:49:27,359 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:49:27,390 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2aefd3b7
   [druid] 2019-02-12 20:49:27,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:49:27,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:27,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:27,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:27,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:27,464 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:27,466 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:27,479 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:27,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:27,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 20:49:27,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1020; bufvoid = 104857600
   [druid] 2019-02-12 20:49:27,479 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2019-02-12 20:49:27,494 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 20:49:27,504 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:27,506 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:27,506 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000001_0' done.
   [druid] 2019-02-12 20:49:27,506 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000001_0
   [druid] 2019-02-12 20:49:27,507 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000002_0
   [druid] 2019-02-12 20:49:27,509 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:27,509 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:27,614 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d644772
   [druid] 2019-02-12 20:49:27,619 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:49:27,680 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:27,681 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:27,681 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:27,681 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:27,681 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:27,683 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:27,692 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:27,692 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:27,716 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:27,719 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:27,719 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000002_0' done.
   [druid] 2019-02-12 20:49:27,719 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000002_0
   [druid] 2019-02-12 20:49:27,720 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000003_0
   [druid] 2019-02-12 20:49:27,721 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:27,721 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:27,834 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2d05ca46
   [druid] 2019-02-12 20:49:27,838 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:49:27,908 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:27,908 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:27,908 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:27,908 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:27,908 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:27,910 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:27,922 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:27,922 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:27,946 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:27,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:27,950 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000003_0' done.
   [druid] 2019-02-12 20:49:27,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000003_0
   [druid] 2019-02-12 20:49:27,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000004_0
   [druid] 2019-02-12 20:49:27,951 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:27,951 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:28,068 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4f6db9bc
   [druid] 2019-02-12 20:49:28,071 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:49:28,136 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:28,137 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:28,137 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:28,137 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:28,137 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:28,138 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:28,147 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:28,148 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:28,171 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:28,174 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:28,174 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000004_0' done.
   [druid] 2019-02-12 20:49:28,174 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000004_0
   [druid] 2019-02-12 20:49:28,174 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000005_0
   [druid] 2019-02-12 20:49:28,175 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:28,176 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:28,304 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@72d755b8
   [druid] 2019-02-12 20:49:28,310 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:49:28,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:28,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:28,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:28,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:28,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:28,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:28,389 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:28,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:28,411 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:28,414 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:28,414 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000005_0' done.
   [druid] 2019-02-12 20:49:28,414 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000005_0
   [druid] 2019-02-12 20:49:28,416 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000006_0
   [druid] 2019-02-12 20:49:28,417 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:28,417 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:28,528 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1e9db7ca
   [druid] 2019-02-12 20:49:28,532 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:49:28,611 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:28,611 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:28,611 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:28,611 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:28,611 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:28,612 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:28,622 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:28,622 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:28,649 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:28,652 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:28,653 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000006_0' done.
   [druid] 2019-02-12 20:49:28,653 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000006_0
   [druid] 2019-02-12 20:49:28,653 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000007_0
   [druid] 2019-02-12 20:49:28,654 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:28,655 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:28,766 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64b0fa65
   [druid] 2019-02-12 20:49:28,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:49:28,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:28,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:28,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:28,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:28,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:28,848 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:28,856 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:28,856 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:28,877 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:28,880 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:28,880 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000007_0' done.
   [druid] 2019-02-12 20:49:28,880 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000007_0
   [druid] 2019-02-12 20:49:28,880 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000008_0
   [druid] 2019-02-12 20:49:28,882 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:28,882 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:28,989 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2afe44b7
   [druid] 2019-02-12 20:49:28,993 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:49:29,071 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:29,071 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:29,071 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:29,071 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:29,071 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:29,072 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:29,079 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:29,079 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:29,102 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:29,104 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:29,104 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000008_0' done.
   [druid] 2019-02-12 20:49:29,104 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000008_0
   [druid] 2019-02-12 20:49:29,104 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_m_000009_0
   [druid] 2019-02-12 20:49:29,106 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:29,106 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:29,223 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@647d7448
   [druid] 2019-02-12 20:49:29,226 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:49:29,302 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:49:29,303 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:49:29,303 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:49:29,303 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:49:29,303 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:49:29,304 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:49:29,314 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:49:29,314 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:49:29,337 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:29,339 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:49:29,339 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_m_000009_0' done.
   [druid] 2019-02-12 20:49:29,339 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_m_000009_0
   [druid] 2019-02-12 20:49:29,339 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:49:29,341 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 20:49:29,341 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1752576265_0001_r_000000_0
   [druid] 2019-02-12 20:49:29,353 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:49:29,354 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:49:29,461 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7bf6989a
   [druid] 2019-02-12 20:49:29,465 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e9e84c4
   [druid] 2019-02-12 20:49:29,482 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 20:49:29,485 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1752576265_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 20:49:29,556 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,565 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000006_0
   [druid] 2019-02-12 20:49:29,570 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-02-12 20:49:29,578 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,581 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000009_0
   [druid] 2019-02-12 20:49:29,581 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
   [druid] 2019-02-12 20:49:29,600 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,602 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000008_0
   [druid] 2019-02-12 20:49:29,602 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
   [druid] 2019-02-12 20:49:29,610 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,611 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000002_0
   [druid] 2019-02-12 20:49:29,611 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
   [druid] 2019-02-12 20:49:29,617 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,618 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000005_0
   [druid] 2019-02-12 20:49:29,618 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
   [druid] 2019-02-12 20:49:29,625 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,626 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000004_0
   [druid] 2019-02-12 20:49:29,626 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 10, usedMemory ->12
   [druid] 2019-02-12 20:49:29,631 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,632 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000007_0
   [druid] 2019-02-12 20:49:29,633 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 12, usedMemory ->14
   [druid] 2019-02-12 20:49:29,638 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000001_0 decomp: 1038 len: 1042 to MEMORY
   [druid] 2019-02-12 20:49:29,639 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1038 bytes from map-output for attempt_local1752576265_0001_m_000001_0
   [druid] 2019-02-12 20:49:29,639 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1038, inMemoryMapOutputs.size() -> 8, commitMemory -> 14, usedMemory ->1052
   [druid] 2019-02-12 20:49:29,645 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000000_0 decomp: 1571 len: 1575 to MEMORY
   [druid] 2019-02-12 20:49:29,646 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1571 bytes from map-output for attempt_local1752576265_0001_m_000000_0
   [druid] 2019-02-12 20:49:29,646 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1571, inMemoryMapOutputs.size() -> 9, commitMemory -> 1052, usedMemory ->2623
   [druid] 2019-02-12 20:49:29,651 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1752576265_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:49:29,652 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1752576265_0001_m_000003_0
   [druid] 2019-02-12 20:49:29,652 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 2623, usedMemory ->2625
   [druid] 2019-02-12 20:49:29,653 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 20:49:29,654 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 20:49:29,654 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 20:49:29,669 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 20:49:29,670 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 2421 bytes
   [druid] 2019-02-12 20:49:29,674 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 2625 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 20:49:29,676 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2611 bytes from disk
   [druid] 2019-02-12 20:49:29,676 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 20:49:29,676 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 20:49:29,677 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2506 bytes
   [druid] 2019-02-12 20:49:29,678 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 20:49:30,144 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 20:49:30,181 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1752576265_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:49:30,182 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 20:49:30,183 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1752576265_0001_r_000000_0' done.
   [druid] 2019-02-12 20:49:30,183 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1752576265_0001_r_000000_0
   [druid] 2019-02-12 20:49:30,183 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 20:49:30,294 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 20:49:30,381 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 20:49:30,386 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1752576265_0001 completed successfully
   [druid] 2019-02-12 20:49:30,424 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=66218
		FILE: Number of bytes written=3354634
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=20
		Map output bytes=2565
		Map output materialized bytes=2665
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=2665
		Reduce input records=20
		Reduce output records=8
		Spilled Records=40
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=8104443904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 20:54:35,590 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:54:35,591 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:54:36,226 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:54:36,274 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:54:36,349 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:54:36,412 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:54:36,575 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local602121562_0001
   [druid] 2019-02-12 20:54:36,821 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:54:36,823 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local602121562_0001
   [druid] 2019-02-12 20:54:36,824 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:54:36,832 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:36,832 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:54:36,841 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:54:36,910 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:54:36,913 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000000_0
   [druid] 2019-02-12 20:54:36,959 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:36,968 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:37,091 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b02e590
   [druid] 2019-02-12 20:54:37,105 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:54:37,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:37,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:37,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:37,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:37,199 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:37,203 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:37,666 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:37,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:37,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 20:54:37,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1545; bufvoid = 104857600
   [druid] 2019-02-12 20:54:37,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
   [druid] 2019-02-12 20:54:37,694 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 20:54:37,706 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:37,716 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:37,717 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000000_0' done.
   [druid] 2019-02-12 20:54:37,717 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000000_0
   [druid] 2019-02-12 20:54:37,717 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000001_0
   [druid] 2019-02-12 20:54:37,719 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:37,719 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:37,821 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2c456b5
   [druid] 2019-02-12 20:54:37,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:54:37,827 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local602121562_0001 running in uber mode : false
   [druid] 2019-02-12 20:54:37,829 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:54:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:37,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:37,890 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:37,891 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:37,916 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:37,916 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:37,917 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 20:54:37,917 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1020; bufvoid = 104857600
   [druid] 2019-02-12 20:54:37,917 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2019-02-12 20:54:37,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 20:54:37,940 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:37,943 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:37,943 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000001_0' done.
   [druid] 2019-02-12 20:54:37,943 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000001_0
   [druid] 2019-02-12 20:54:37,943 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000002_0
   [druid] 2019-02-12 20:54:37,945 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:37,946 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:38,053 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13f6221d
   [druid] 2019-02-12 20:54:38,056 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:54:38,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:38,127 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:38,127 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:38,127 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:38,127 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:38,129 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:38,136 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:38,136 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:38,159 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:38,161 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:38,161 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000002_0' done.
   [druid] 2019-02-12 20:54:38,162 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000002_0
   [druid] 2019-02-12 20:54:38,162 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000003_0
   [druid] 2019-02-12 20:54:38,164 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:38,164 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:38,268 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@303fb684
   [druid] 2019-02-12 20:54:38,271 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:54:38,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:38,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:38,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:38,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:38,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:38,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:38,337 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:38,337 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:38,361 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:38,364 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:38,364 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000003_0' done.
   [druid] 2019-02-12 20:54:38,364 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000003_0
   [druid] 2019-02-12 20:54:38,364 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000004_0
   [druid] 2019-02-12 20:54:38,365 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:38,366 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:38,486 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5a2121ac
   [druid] 2019-02-12 20:54:38,488 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:54:38,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:38,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:38,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:38,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:38,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:38,559 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:38,571 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:38,571 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:38,593 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:38,595 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:38,596 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000004_0' done.
   [druid] 2019-02-12 20:54:38,596 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000004_0
   [druid] 2019-02-12 20:54:38,596 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000005_0
   [druid] 2019-02-12 20:54:38,597 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:38,597 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:38,710 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@49d093a2
   [druid] 2019-02-12 20:54:38,714 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:54:38,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:38,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:38,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:38,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:38,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:38,785 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:38,792 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:38,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:38,814 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:38,817 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:38,817 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000005_0' done.
   [druid] 2019-02-12 20:54:38,817 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000005_0
   [druid] 2019-02-12 20:54:38,818 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000006_0
   [druid] 2019-02-12 20:54:38,822 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:38,822 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:38,926 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@29339f2f
   [druid] 2019-02-12 20:54:38,928 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:54:38,992 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:38,992 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:38,992 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:38,992 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:38,992 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:38,993 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:39,002 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:39,002 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:39,029 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:39,031 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:39,032 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000006_0' done.
   [druid] 2019-02-12 20:54:39,032 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000006_0
   [druid] 2019-02-12 20:54:39,032 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000007_0
   [druid] 2019-02-12 20:54:39,037 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:39,037 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:39,169 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f0d46c0
   [druid] 2019-02-12 20:54:39,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:54:39,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:39,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:39,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:39,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:39,234 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:39,236 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:39,243 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:39,244 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:39,266 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:39,268 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:39,269 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000007_0' done.
   [druid] 2019-02-12 20:54:39,269 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000007_0
   [druid] 2019-02-12 20:54:39,269 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000008_0
   [druid] 2019-02-12 20:54:39,271 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:39,271 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:39,378 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@764d12a9
   [druid] 2019-02-12 20:54:39,382 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:54:39,442 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:39,443 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:39,443 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:39,443 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:39,443 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:39,444 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:39,452 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:39,452 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:39,472 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:39,475 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:39,475 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000008_0' done.
   [druid] 2019-02-12 20:54:39,475 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000008_0
   [druid] 2019-02-12 20:54:39,475 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_m_000009_0
   [druid] 2019-02-12 20:54:39,477 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:39,477 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:39,611 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52c65ef6
   [druid] 2019-02-12 20:54:39,614 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:54:39,691 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:54:39,691 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:54:39,691 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:54:39,691 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:54:39,691 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:54:39,693 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:54:39,700 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:54:39,700 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:54:39,719 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:39,721 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:54:39,722 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_m_000009_0' done.
   [druid] 2019-02-12 20:54:39,722 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_m_000009_0
   [druid] 2019-02-12 20:54:39,722 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:54:39,725 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 20:54:39,726 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local602121562_0001_r_000000_0
   [druid] 2019-02-12 20:54:39,739 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:54:39,739 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:54:39,842 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@614e4784
   [druid] 2019-02-12 20:54:39,846 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e81caef
   [druid] 2019-02-12 20:54:39,860 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 20:54:39,863 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local602121562_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 20:54:39,941 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:39,947 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000002_0
   [druid] 2019-02-12 20:54:39,950 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-02-12 20:54:39,959 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:39,962 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000005_0
   [druid] 2019-02-12 20:54:39,962 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
   [druid] 2019-02-12 20:54:39,969 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:39,970 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000008_0
   [druid] 2019-02-12 20:54:39,971 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
   [druid] 2019-02-12 20:54:39,984 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:39,987 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000003_0
   [druid] 2019-02-12 20:54:39,988 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
   [druid] 2019-02-12 20:54:39,995 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:39,997 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000006_0
   [druid] 2019-02-12 20:54:39,997 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
   [druid] 2019-02-12 20:54:40,005 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:40,006 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000009_0
   [druid] 2019-02-12 20:54:40,006 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 10, usedMemory ->12
   [druid] 2019-02-12 20:54:40,012 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:40,013 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000007_0
   [druid] 2019-02-12 20:54:40,013 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 12, usedMemory ->14
   [druid] 2019-02-12 20:54:40,018 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000000_0 decomp: 1571 len: 1575 to MEMORY
   [druid] 2019-02-12 20:54:40,018 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1571 bytes from map-output for attempt_local602121562_0001_m_000000_0
   [druid] 2019-02-12 20:54:40,018 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1571, inMemoryMapOutputs.size() -> 8, commitMemory -> 14, usedMemory ->1585
   [druid] 2019-02-12 20:54:40,025 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000001_0 decomp: 1038 len: 1042 to MEMORY
   [druid] 2019-02-12 20:54:40,025 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1038 bytes from map-output for attempt_local602121562_0001_m_000001_0
   [druid] 2019-02-12 20:54:40,025 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1038, inMemoryMapOutputs.size() -> 9, commitMemory -> 1585, usedMemory ->2623
   [druid] 2019-02-12 20:54:40,031 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local602121562_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:54:40,031 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local602121562_0001_m_000004_0
   [druid] 2019-02-12 20:54:40,031 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 2623, usedMemory ->2625
   [druid] 2019-02-12 20:54:40,032 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 20:54:40,032 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 20:54:40,033 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 20:54:40,047 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 20:54:40,047 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 2421 bytes
   [druid] 2019-02-12 20:54:40,051 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 2625 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 20:54:40,052 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2611 bytes from disk
   [druid] 2019-02-12 20:54:40,053 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 20:54:40,054 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 20:54:40,055 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2506 bytes
   [druid] 2019-02-12 20:54:40,055 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 20:54:40,499 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 20:54:40,534 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local602121562_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:54:40,536 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 20:54:40,536 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local602121562_0001_r_000000_0' done.
   [druid] 2019-02-12 20:54:40,536 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local602121562_0001_r_000000_0
   [druid] 2019-02-12 20:54:40,537 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 20:54:40,642 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 20:54:40,834 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 20:54:40,835 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local602121562_0001 completed successfully
   [druid] 2019-02-12 20:54:40,863 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=66218
		FILE: Number of bytes written=3337628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=20
		Map output bytes=2565
		Map output materialized bytes=2665
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=2665
		Reduce input records=20
		Reduce output records=8
		Spilled Records=40
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=8107589632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 20:57:51,150 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 20:57:51,153 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 20:57:51,828 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 20:57:51,870 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 20:57:51,977 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 20:57:52,044 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 20:57:52,209 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local649875001_0001
   [druid] 2019-02-12 20:57:52,432 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 20:57:52,434 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local649875001_0001
   [druid] 2019-02-12 20:57:52,442 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 20:57:52,451 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:52,451 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 20:57:52,461 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 20:57:52,530 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 20:57:52,533 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000000_0
   [druid] 2019-02-12 20:57:52,567 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:52,575 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:52,694 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@af56a54
   [druid] 2019-02-12 20:57:52,704 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 20:57:52,794 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:52,794 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:52,794 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:52,794 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:52,794 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:52,799 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:53,324 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:53,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:53,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 20:57:53,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1545; bufvoid = 104857600
   [druid] 2019-02-12 20:57:53,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
   [druid] 2019-02-12 20:57:53,349 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 20:57:53,359 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:53,372 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:53,372 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000000_0' done.
   [druid] 2019-02-12 20:57:53,372 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000000_0
   [druid] 2019-02-12 20:57:53,372 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000001_0
   [druid] 2019-02-12 20:57:53,374 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:53,374 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:53,437 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local649875001_0001 running in uber mode : false
   [druid] 2019-02-12 20:57:53,439 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 20:57:53,477 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@59d080e5
   [druid] 2019-02-12 20:57:53,480 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 20:57:53,545 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:53,545 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:53,545 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:53,545 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:53,545 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:53,546 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:53,561 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:53,561 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:53,561 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 20:57:53,561 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1020; bufvoid = 104857600
   [druid] 2019-02-12 20:57:53,561 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2019-02-12 20:57:53,575 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 20:57:53,585 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:53,587 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:53,588 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000001_0' done.
   [druid] 2019-02-12 20:57:53,588 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000001_0
   [druid] 2019-02-12 20:57:53,588 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000002_0
   [druid] 2019-02-12 20:57:53,590 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:53,590 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:53,712 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@746a2071
   [druid] 2019-02-12 20:57:53,715 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 20:57:53,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:53,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:53,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:53,792 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:53,793 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:53,794 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:53,803 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:53,803 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:53,824 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:53,829 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:53,829 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000002_0' done.
   [druid] 2019-02-12 20:57:53,829 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000002_0
   [druid] 2019-02-12 20:57:53,829 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000003_0
   [druid] 2019-02-12 20:57:53,832 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:53,832 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:53,940 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@505cc76a
   [druid] 2019-02-12 20:57:53,943 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 20:57:54,012 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:54,012 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:54,012 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:54,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:54,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:54,014 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:54,023 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:54,023 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:54,048 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:54,051 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:54,051 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000003_0' done.
   [druid] 2019-02-12 20:57:54,051 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000003_0
   [druid] 2019-02-12 20:57:54,051 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000004_0
   [druid] 2019-02-12 20:57:54,053 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:54,053 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:54,176 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37ee0c04
   [druid] 2019-02-12 20:57:54,179 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 20:57:54,248 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:54,248 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:54,248 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:54,248 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:54,248 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:54,249 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:54,260 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:54,260 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:54,281 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:54,284 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:54,285 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000004_0' done.
   [druid] 2019-02-12 20:57:54,285 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000004_0
   [druid] 2019-02-12 20:57:54,285 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000005_0
   [druid] 2019-02-12 20:57:54,286 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:54,286 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:54,396 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71ac6869
   [druid] 2019-02-12 20:57:54,401 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 20:57:54,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:54,469 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:54,469 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:54,469 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:54,469 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:54,470 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:54,514 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:54,514 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:54,533 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:54,536 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:54,536 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000005_0' done.
   [druid] 2019-02-12 20:57:54,536 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000005_0
   [druid] 2019-02-12 20:57:54,536 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000006_0
   [druid] 2019-02-12 20:57:54,537 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:54,537 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:54,652 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5828febe
   [druid] 2019-02-12 20:57:54,655 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 20:57:54,724 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:54,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:54,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:54,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:54,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:54,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:54,735 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:54,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:54,757 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:54,760 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:54,760 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000006_0' done.
   [druid] 2019-02-12 20:57:54,760 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000006_0
   [druid] 2019-02-12 20:57:54,760 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000007_0
   [druid] 2019-02-12 20:57:54,761 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:54,762 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:54,883 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3950c3f1
   [druid] 2019-02-12 20:57:54,886 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 20:57:54,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:54,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:54,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:54,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:54,954 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:54,956 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:54,965 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:54,965 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:54,985 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:54,988 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:54,989 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000007_0' done.
   [druid] 2019-02-12 20:57:54,989 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000007_0
   [druid] 2019-02-12 20:57:54,989 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000008_0
   [druid] 2019-02-12 20:57:54,990 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:54,990 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:55,111 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7d4b5db4
   [druid] 2019-02-12 20:57:55,114 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 20:57:55,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:55,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:55,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:55,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:55,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:55,144 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:55,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:55,151 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:55,172 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:55,174 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:55,174 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000008_0' done.
   [druid] 2019-02-12 20:57:55,174 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000008_0
   [druid] 2019-02-12 20:57:55,174 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_m_000009_0
   [druid] 2019-02-12 20:57:55,175 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:55,175 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:55,291 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1a211c2d
   [druid] 2019-02-12 20:57:55,294 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 20:57:55,354 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 20:57:55,354 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 20:57:55,354 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 20:57:55,354 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 20:57:55,354 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 20:57:55,355 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 20:57:55,363 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 20:57:55,364 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 20:57:55,398 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:55,400 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 20:57:55,400 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_m_000009_0' done.
   [druid] 2019-02-12 20:57:55,400 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_m_000009_0
   [druid] 2019-02-12 20:57:55,400 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 20:57:55,405 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 20:57:55,410 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local649875001_0001_r_000000_0
   [druid] 2019-02-12 20:57:55,422 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 20:57:55,422 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 20:57:55,530 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@60665e9f
   [druid] 2019-02-12 20:57:55,534 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@545ec7aa
   [druid] 2019-02-12 20:57:55,551 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 20:57:55,554 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local649875001_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 20:57:55,622 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000000_0 decomp: 1571 len: 1575 to MEMORY
   [druid] 2019-02-12 20:57:55,630 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1571 bytes from map-output for attempt_local649875001_0001_m_000000_0
   [druid] 2019-02-12 20:57:55,633 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1571, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1571
   [druid] 2019-02-12 20:57:55,644 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,645 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000003_0
   [druid] 2019-02-12 20:57:55,646 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 1571, usedMemory ->1573
   [druid] 2019-02-12 20:57:55,655 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,659 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000006_0
   [druid] 2019-02-12 20:57:55,659 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 1573, usedMemory ->1575
   [druid] 2019-02-12 20:57:55,680 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,682 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000009_0
   [druid] 2019-02-12 20:57:55,682 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 1575, usedMemory ->1577
   [druid] 2019-02-12 20:57:55,692 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,694 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000002_0
   [druid] 2019-02-12 20:57:55,694 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 1577, usedMemory ->1579
   [druid] 2019-02-12 20:57:55,703 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,704 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000005_0
   [druid] 2019-02-12 20:57:55,704 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 1579, usedMemory ->1581
   [druid] 2019-02-12 20:57:55,711 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,712 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000008_0
   [druid] 2019-02-12 20:57:55,712 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 1581, usedMemory ->1583
   [druid] 2019-02-12 20:57:55,720 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000001_0 decomp: 1038 len: 1042 to MEMORY
   [druid] 2019-02-12 20:57:55,721 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1038 bytes from map-output for attempt_local649875001_0001_m_000001_0
   [druid] 2019-02-12 20:57:55,721 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1038, inMemoryMapOutputs.size() -> 8, commitMemory -> 1583, usedMemory ->2621
   [druid] 2019-02-12 20:57:55,728 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,730 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000004_0
   [druid] 2019-02-12 20:57:55,730 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 2621, usedMemory ->2623
   [druid] 2019-02-12 20:57:55,735 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local649875001_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 20:57:55,736 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local649875001_0001_m_000007_0
   [druid] 2019-02-12 20:57:55,736 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 2623, usedMemory ->2625
   [druid] 2019-02-12 20:57:55,737 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 20:57:55,738 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 20:57:55,738 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 20:57:55,757 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 20:57:55,757 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 2421 bytes
   [druid] 2019-02-12 20:57:55,761 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 2625 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 20:57:55,763 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2611 bytes from disk
   [druid] 2019-02-12 20:57:55,764 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 20:57:55,764 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 20:57:55,765 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2506 bytes
   [druid] 2019-02-12 20:57:55,766 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 20:57:56,121 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 20:57:56,182 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 20:57:56,183 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 20:57:56,183 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 20:57:56,183 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 20:57:56,201 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 20:57:56,201 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 20:57:56,208 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local649875001_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 20:57:56,209 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 20:57:56,210 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local649875001_0001_r_000000_0' done.
   [druid] 2019-02-12 20:57:56,210 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local649875001_0001_r_000000_0
   [druid] 2019-02-12 20:57:56,210 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 20:57:56,316 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 20:57:56,443 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 20:57:56,444 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local649875001_0001 completed successfully
   [druid] 2019-02-12 20:57:56,473 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=66218
		FILE: Number of bytes written=3337628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=20
		Map output bytes=2565
		Map output materialized bytes=2665
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=2665
		Reduce input records=20
		Reduce output records=8
		Spilled Records=40
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=8066695168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 21:00:49,014 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 21:00:49,016 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 21:00:49,664 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 21:00:49,707 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 21:00:49,830 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 21:00:49,894 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 21:00:50,061 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1911076105_0001
   [druid] 2019-02-12 21:00:50,298 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 21:00:50,303 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1911076105_0001
   [druid] 2019-02-12 21:00:50,309 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 21:00:50,317 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:50,317 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 21:00:50,328 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 21:00:50,395 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 21:00:50,398 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000000_0
   [druid] 2019-02-12 21:00:50,432 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:50,439 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:50,557 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6555c4e0
   [druid] 2019-02-12 21:00:50,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 21:00:50,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:50,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:50,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:50,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:50,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:50,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:51,138 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:51,141 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:51,141 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 21:00:51,141 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1545; bufvoid = 104857600
   [druid] 2019-02-12 21:00:51,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
   [druid] 2019-02-12 21:00:51,162 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 21:00:51,171 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:51,183 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:51,183 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000000_0' done.
   [druid] 2019-02-12 21:00:51,184 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000000_0
   [druid] 2019-02-12 21:00:51,184 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000001_0
   [druid] 2019-02-12 21:00:51,186 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:51,187 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:51,291 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@779adfa0
   [druid] 2019-02-12 21:00:51,294 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 21:00:51,306 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1911076105_0001 running in uber mode : false
   [druid] 2019-02-12 21:00:51,309 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 21:00:51,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:51,358 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:51,358 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:51,358 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:51,358 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:51,359 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:51,375 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:51,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:51,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 21:00:51,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1020; bufvoid = 104857600
   [druid] 2019-02-12 21:00:51,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2019-02-12 21:00:51,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 21:00:51,398 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:51,401 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:51,401 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000001_0' done.
   [druid] 2019-02-12 21:00:51,401 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000001_0
   [druid] 2019-02-12 21:00:51,401 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000002_0
   [druid] 2019-02-12 21:00:51,404 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:51,404 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:51,511 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5fbaab44
   [druid] 2019-02-12 21:00:51,514 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 21:00:51,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:51,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:51,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:51,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:51,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:51,575 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:51,586 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:51,587 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:51,612 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:51,615 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:51,615 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000002_0' done.
   [druid] 2019-02-12 21:00:51,616 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000002_0
   [druid] 2019-02-12 21:00:51,616 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000003_0
   [druid] 2019-02-12 21:00:51,618 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:51,618 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:51,735 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@75655a0d
   [druid] 2019-02-12 21:00:51,739 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 21:00:51,802 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:51,802 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:51,802 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:51,802 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:51,802 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:51,803 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:51,810 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:51,810 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:51,830 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:51,833 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:51,834 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000003_0' done.
   [druid] 2019-02-12 21:00:51,834 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000003_0
   [druid] 2019-02-12 21:00:51,834 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000004_0
   [druid] 2019-02-12 21:00:51,835 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:51,836 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:51,956 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2c4356d9
   [druid] 2019-02-12 21:00:51,959 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 21:00:52,027 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:52,028 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:52,028 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:52,028 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:52,028 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:52,029 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:52,039 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:52,039 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:52,063 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:52,067 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:52,067 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000004_0' done.
   [druid] 2019-02-12 21:00:52,067 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000004_0
   [druid] 2019-02-12 21:00:52,067 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000005_0
   [druid] 2019-02-12 21:00:52,068 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:52,069 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:52,190 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@469f8ea5
   [druid] 2019-02-12 21:00:52,196 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 21:00:52,265 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:52,265 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:52,265 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:52,265 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:52,265 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:52,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:52,276 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:52,276 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:52,298 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:52,301 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:52,303 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000005_0' done.
   [druid] 2019-02-12 21:00:52,304 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000005_0
   [druid] 2019-02-12 21:00:52,304 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000006_0
   [druid] 2019-02-12 21:00:52,305 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:52,306 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:52,418 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@312e2442
   [druid] 2019-02-12 21:00:52,422 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 21:00:52,484 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:52,484 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:52,484 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:52,484 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:52,484 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:52,485 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:52,493 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:52,494 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:52,518 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:52,521 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:52,521 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000006_0' done.
   [druid] 2019-02-12 21:00:52,521 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000006_0
   [druid] 2019-02-12 21:00:52,521 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000007_0
   [druid] 2019-02-12 21:00:52,522 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:52,522 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:52,654 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@47e9421a
   [druid] 2019-02-12 21:00:52,657 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 21:00:52,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:52,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:52,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:52,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:52,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:52,733 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:52,743 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:52,743 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:52,770 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:52,772 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:52,773 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000007_0' done.
   [druid] 2019-02-12 21:00:52,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000007_0
   [druid] 2019-02-12 21:00:52,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000008_0
   [druid] 2019-02-12 21:00:52,774 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:52,774 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:52,900 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@33bdb5ee
   [druid] 2019-02-12 21:00:52,903 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 21:00:52,977 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:52,977 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:52,977 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:52,977 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:52,977 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:52,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:53,004 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:53,004 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:53,028 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:53,030 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:53,030 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000008_0' done.
   [druid] 2019-02-12 21:00:53,031 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000008_0
   [druid] 2019-02-12 21:00:53,031 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_m_000009_0
   [druid] 2019-02-12 21:00:53,032 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:53,032 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:53,157 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5aa2c13b
   [druid] 2019-02-12 21:00:53,159 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 21:00:53,190 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:00:53,190 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:00:53,190 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:00:53,190 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:00:53,190 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:00:53,191 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:00:53,199 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:00:53,199 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:00:53,221 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:53,223 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:00:53,223 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_m_000009_0' done.
   [druid] 2019-02-12 21:00:53,223 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_m_000009_0
   [druid] 2019-02-12 21:00:53,223 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 21:00:53,227 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 21:00:53,228 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911076105_0001_r_000000_0
   [druid] 2019-02-12 21:00:53,244 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:00:53,244 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:00:53,350 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@54f342f9
   [druid] 2019-02-12 21:00:53,361 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5c8e06a5
   [druid] 2019-02-12 21:00:53,377 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 21:00:53,380 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1911076105_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 21:00:53,446 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,454 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000007_0
   [druid] 2019-02-12 21:00:53,458 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-02-12 21:00:53,475 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000001_0 decomp: 1038 len: 1042 to MEMORY
   [druid] 2019-02-12 21:00:53,476 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1038 bytes from map-output for attempt_local1911076105_0001_m_000001_0
   [druid] 2019-02-12 21:00:53,477 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1038, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->1040
   [druid] 2019-02-12 21:00:53,492 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,493 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000004_0
   [druid] 2019-02-12 21:00:53,493 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 1040, usedMemory ->1042
   [druid] 2019-02-12 21:00:53,507 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,508 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000005_0
   [druid] 2019-02-12 21:00:53,508 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 1042, usedMemory ->1044
   [druid] 2019-02-12 21:00:53,514 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,516 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000008_0
   [druid] 2019-02-12 21:00:53,516 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 1044, usedMemory ->1046
   [druid] 2019-02-12 21:00:53,522 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,523 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000002_0
   [druid] 2019-02-12 21:00:53,523 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 1046, usedMemory ->1048
   [druid] 2019-02-12 21:00:53,528 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,529 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000009_0
   [druid] 2019-02-12 21:00:53,529 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 1048, usedMemory ->1050
   [druid] 2019-02-12 21:00:53,533 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,534 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000003_0
   [druid] 2019-02-12 21:00:53,534 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 1050, usedMemory ->1052
   [druid] 2019-02-12 21:00:53,539 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:00:53,540 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1911076105_0001_m_000006_0
   [druid] 2019-02-12 21:00:53,540 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 1052, usedMemory ->1054
   [druid] 2019-02-12 21:00:53,545 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1911076105_0001_m_000000_0 decomp: 1571 len: 1575 to MEMORY
   [druid] 2019-02-12 21:00:53,546 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1571 bytes from map-output for attempt_local1911076105_0001_m_000000_0
   [druid] 2019-02-12 21:00:53,546 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1571, inMemoryMapOutputs.size() -> 10, commitMemory -> 1054, usedMemory ->2625
   [druid] 2019-02-12 21:00:53,546 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 21:00:53,547 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 21:00:53,547 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 21:00:53,562 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 21:00:53,563 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 2421 bytes
   [druid] 2019-02-12 21:00:53,567 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 2625 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 21:00:53,568 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2611 bytes from disk
   [druid] 2019-02-12 21:00:53,569 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 21:00:53,569 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 21:00:53,570 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2506 bytes
   [druid] 2019-02-12 21:00:53,571 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 21:00:53,968 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 21:00:54,043 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 21:00:54,044 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 21:00:54,044 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 21:00:54,045 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 21:00:54,061 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 21:00:54,062 [pool-6-thread-1] WARN  sis.mr.nu.NewUserOutputWritter {1} - ps
   [druid] 2019-02-12 21:00:54,070 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1911076105_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:00:54,072 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 21:00:54,072 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1911076105_0001_r_000000_0' done.
   [druid] 2019-02-12 21:00:54,072 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1911076105_0001_r_000000_0
   [druid] 2019-02-12 21:00:54,072 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 21:00:54,178 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 21:00:54,313 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 21:00:54,314 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1911076105_0001 completed successfully
   [druid] 2019-02-12 21:00:54,344 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=66218
		FILE: Number of bytes written=3354634
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=20
		Map output bytes=2565
		Map output materialized bytes=2665
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=2665
		Reduce input records=20
		Reduce output records=8
		Spilled Records=40
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=8189902848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 21:05:08,639 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 21:05:08,641 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 21:05:09,347 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 21:05:09,388 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 21:05:09,504 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 21:05:09,585 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 21:05:09,748 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local806254151_0001
   [druid] 2019-02-12 21:05:09,993 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 21:05:09,995 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local806254151_0001
   [druid] 2019-02-12 21:05:10,002 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 21:05:10,014 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:10,014 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 21:05:10,024 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 21:05:10,100 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 21:05:10,104 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000000_0
   [druid] 2019-02-12 21:05:10,141 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:10,148 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:10,266 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5cbda731
   [druid] 2019-02-12 21:05:10,277 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 21:05:10,368 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:10,368 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:10,368 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:10,368 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:10,368 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:10,373 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:10,840 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:10,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:10,847 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 21:05:10,847 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1545; bufvoid = 104857600
   [druid] 2019-02-12 21:05:10,847 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
   [druid] 2019-02-12 21:05:10,868 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 21:05:10,888 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:10,900 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:10,900 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000000_0' done.
   [druid] 2019-02-12 21:05:10,900 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000000_0
   [druid] 2019-02-12 21:05:10,900 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000001_0
   [druid] 2019-02-12 21:05:10,901 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:10,901 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:11,002 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local806254151_0001 running in uber mode : false
   [druid] 2019-02-12 21:05:11,003 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c0bce72
   [druid] 2019-02-12 21:05:11,004 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 21:05:11,006 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 21:05:11,072 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:11,072 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:11,072 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:11,072 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:11,072 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:11,073 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:11,089 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:11,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:11,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 21:05:11,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1020; bufvoid = 104857600
   [druid] 2019-02-12 21:05:11,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2019-02-12 21:05:11,105 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 21:05:11,117 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:11,121 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:11,121 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000001_0' done.
   [druid] 2019-02-12 21:05:11,121 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000001_0
   [druid] 2019-02-12 21:05:11,121 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000002_0
   [druid] 2019-02-12 21:05:11,123 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:11,123 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:11,245 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6c45bdf5
   [druid] 2019-02-12 21:05:11,247 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 21:05:11,316 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:11,316 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:11,317 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:11,317 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:11,317 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:11,318 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:11,326 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:11,327 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:11,349 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:11,352 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:11,353 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000002_0' done.
   [druid] 2019-02-12 21:05:11,353 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000002_0
   [druid] 2019-02-12 21:05:11,354 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000003_0
   [druid] 2019-02-12 21:05:11,355 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:11,356 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:11,469 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7313aea3
   [druid] 2019-02-12 21:05:11,472 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 21:05:11,536 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:11,536 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:11,536 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:11,537 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:11,537 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:11,537 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:11,547 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:11,548 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:11,573 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:11,577 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:11,578 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000003_0' done.
   [druid] 2019-02-12 21:05:11,578 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000003_0
   [druid] 2019-02-12 21:05:11,578 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000004_0
   [druid] 2019-02-12 21:05:11,580 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:11,580 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:11,706 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1809d69d
   [druid] 2019-02-12 21:05:11,709 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 21:05:11,777 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:11,777 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:11,777 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:11,777 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:11,777 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:11,778 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:11,803 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:11,803 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:11,825 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:11,828 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:11,828 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000004_0' done.
   [druid] 2019-02-12 21:05:11,829 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000004_0
   [druid] 2019-02-12 21:05:11,829 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000005_0
   [druid] 2019-02-12 21:05:11,830 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:11,831 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:11,943 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7da7a0b2
   [druid] 2019-02-12 21:05:11,948 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 21:05:12,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:12,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:12,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:12,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:12,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:12,012 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:12,020 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:12,020 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:12,040 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:12,043 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:12,043 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000005_0' done.
   [druid] 2019-02-12 21:05:12,043 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000005_0
   [druid] 2019-02-12 21:05:12,044 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000006_0
   [druid] 2019-02-12 21:05:12,045 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:12,045 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:12,157 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@41114496
   [druid] 2019-02-12 21:05:12,161 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 21:05:12,223 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:12,223 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:12,223 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:12,223 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:12,223 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:12,227 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:12,238 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:12,238 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:12,261 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:12,262 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:12,263 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000006_0' done.
   [druid] 2019-02-12 21:05:12,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000006_0
   [druid] 2019-02-12 21:05:12,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000007_0
   [druid] 2019-02-12 21:05:12,264 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:12,264 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:12,387 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e64b531
   [druid] 2019-02-12 21:05:12,390 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 21:05:12,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:12,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:12,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:12,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:12,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:12,461 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:12,469 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:12,469 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:12,491 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:12,495 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:12,495 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000007_0' done.
   [druid] 2019-02-12 21:05:12,495 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000007_0
   [druid] 2019-02-12 21:05:12,495 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000008_0
   [druid] 2019-02-12 21:05:12,497 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:12,497 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:12,616 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@377a9629
   [druid] 2019-02-12 21:05:12,618 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 21:05:12,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:12,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:12,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:12,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:12,688 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:12,689 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:12,696 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:12,697 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:12,717 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:12,719 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:12,719 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000008_0' done.
   [druid] 2019-02-12 21:05:12,719 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000008_0
   [druid] 2019-02-12 21:05:12,719 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_m_000009_0
   [druid] 2019-02-12 21:05:12,720 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:12,720 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:12,830 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@256d6d2c
   [druid] 2019-02-12 21:05:12,833 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 21:05:12,895 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 21:05:12,895 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 21:05:12,895 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 21:05:12,895 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 21:05:12,895 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 21:05:12,896 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 21:05:12,905 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 21:05:12,905 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 21:05:12,926 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:12,928 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 21:05:12,928 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_m_000009_0' done.
   [druid] 2019-02-12 21:05:12,928 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_m_000009_0
   [druid] 2019-02-12 21:05:12,929 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 21:05:12,932 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 21:05:12,933 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local806254151_0001_r_000000_0
   [druid] 2019-02-12 21:05:12,946 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 21:05:12,946 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 21:05:13,058 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3cfdeb4b
   [druid] 2019-02-12 21:05:13,063 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@740c4aa7
   [druid] 2019-02-12 21:05:13,077 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 21:05:13,080 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local806254151_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 21:05:13,154 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,162 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000009_0
   [druid] 2019-02-12 21:05:13,167 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-02-12 21:05:13,179 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,182 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000006_0
   [druid] 2019-02-12 21:05:13,182 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
   [druid] 2019-02-12 21:05:13,201 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,204 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000003_0
   [druid] 2019-02-12 21:05:13,204 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
   [druid] 2019-02-12 21:05:13,214 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000000_0 decomp: 1571 len: 1575 to MEMORY
   [druid] 2019-02-12 21:05:13,216 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1571 bytes from map-output for attempt_local806254151_0001_m_000000_0
   [druid] 2019-02-12 21:05:13,216 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1571, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->1577
   [druid] 2019-02-12 21:05:13,221 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,222 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000007_0
   [druid] 2019-02-12 21:05:13,222 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 1577, usedMemory ->1579
   [druid] 2019-02-12 21:05:13,228 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,229 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000004_0
   [druid] 2019-02-12 21:05:13,229 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 1579, usedMemory ->1581
   [druid] 2019-02-12 21:05:13,236 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000001_0 decomp: 1038 len: 1042 to MEMORY
   [druid] 2019-02-12 21:05:13,237 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1038 bytes from map-output for attempt_local806254151_0001_m_000001_0
   [druid] 2019-02-12 21:05:13,237 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1038, inMemoryMapOutputs.size() -> 7, commitMemory -> 1581, usedMemory ->2619
   [druid] 2019-02-12 21:05:13,242 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,243 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000008_0
   [druid] 2019-02-12 21:05:13,243 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 2619, usedMemory ->2621
   [druid] 2019-02-12 21:05:13,249 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,250 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000005_0
   [druid] 2019-02-12 21:05:13,250 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 2621, usedMemory ->2623
   [druid] 2019-02-12 21:05:13,255 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local806254151_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 21:05:13,256 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local806254151_0001_m_000002_0
   [druid] 2019-02-12 21:05:13,256 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 2623, usedMemory ->2625
   [druid] 2019-02-12 21:05:13,256 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 21:05:13,257 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 21:05:13,257 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 21:05:13,272 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 21:05:13,272 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 2421 bytes
   [druid] 2019-02-12 21:05:13,276 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 2625 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 21:05:13,277 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2611 bytes from disk
   [druid] 2019-02-12 21:05:13,278 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 21:05:13,279 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 21:05:13,280 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2506 bytes
   [druid] 2019-02-12 21:05:13,280 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 21:05:13,709 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 21:05:13,753 [pool-6-thread-1] WARN  .analysis.mr.nu.NewUserWritter {1} - ps
   [druid] 2019-02-12 21:05:13,753 [pool-6-thread-1] WARN  .analysis.mr.nu.NewUserWritter {1} - ps
   [druid] 2019-02-12 21:05:13,754 [pool-6-thread-1] WARN  .analysis.mr.nu.NewUserWritter {1} - ps
   [druid] 2019-02-12 21:05:13,754 [pool-6-thread-1] WARN  .analysis.mr.nu.NewUserWritter {1} - ps
   [druid] 2019-02-12 21:05:13,764 [pool-6-thread-1] WARN  .analysis.mr.nu.NewUserWritter {1} - ps
   [druid] 2019-02-12 21:05:13,765 [pool-6-thread-1] WARN  .analysis.mr.nu.NewUserWritter {1} - ps
   [druid] 2019-02-12 21:05:13,822 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local806254151_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 21:05:13,823 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 21:05:13,823 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local806254151_0001_r_000000_0' done.
   [druid] 2019-02-12 21:05:13,823 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local806254151_0001_r_000000_0
   [druid] 2019-02-12 21:05:13,823 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 21:05:13,932 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 21:05:14,011 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 21:05:14,012 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local806254151_0001 completed successfully
   [druid] 2019-02-12 21:05:14,052 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=66218
		FILE: Number of bytes written=3337364
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=20
		Map output bytes=2565
		Map output materialized bytes=2665
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=2665
		Reduce input records=20
		Reduce output records=8
		Spilled Records=40
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=8105492480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 22:00:53,737 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 22:00:53,739 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 22:00:54,429 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 22:00:54,468 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 22:00:54,543 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 10
   [druid] 2019-02-12 22:00:54,594 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:10
   [druid] 2019-02-12 22:00:54,760 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1560666486_0001
   [druid] 2019-02-12 22:00:55,010 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 22:00:55,011 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1560666486_0001
   [druid] 2019-02-12 22:00:55,020 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 22:00:55,030 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:55,030 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 22:00:55,038 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 22:00:55,117 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 22:00:55,120 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000000_0
   [druid] 2019-02-12 22:00:55,163 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:55,171 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:55,402 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@49228147
   [druid] 2019-02-12 22:00:55,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00000:0+40449
   [druid] 2019-02-12 22:00:55,583 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:55,583 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:55,583 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:55,583 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:55,583 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:55,589 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:56,015 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1560666486_0001 running in uber mode : false
   [druid] 2019-02-12 22:00:56,018 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-02-12 22:00:56,093 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:56,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:56,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 22:00:56,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1545; bufvoid = 104857600
   [druid] 2019-02-12 22:00:56,097 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
   [druid] 2019-02-12 22:00:56,142 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 22:00:56,154 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:56,167 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:56,168 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000000_0' done.
   [druid] 2019-02-12 22:00:56,168 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000000_0
   [druid] 2019-02-12 22:00:56,168 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000001_0
   [druid] 2019-02-12 22:00:56,169 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:56,169 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:56,280 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2046f409
   [druid] 2019-02-12 22:00:56,284 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00001:0+22494
   [druid] 2019-02-12 22:00:56,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:56,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:56,369 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:56,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:56,370 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:56,371 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:56,414 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:56,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:56,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 22:00:56,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1020; bufvoid = 104857600
   [druid] 2019-02-12 22:00:56,414 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2019-02-12 22:00:56,428 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 22:00:56,437 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:56,439 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:56,440 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000001_0' done.
   [druid] 2019-02-12 22:00:56,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000001_0
   [druid] 2019-02-12 22:00:56,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000002_0
   [druid] 2019-02-12 22:00:56,441 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:56,441 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:56,565 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@24c851f8
   [druid] 2019-02-12 22:00:56,569 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00002:0+4835
   [druid] 2019-02-12 22:00:56,652 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:56,652 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:56,653 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:56,653 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:56,653 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:56,654 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:56,662 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:56,662 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:56,684 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:56,687 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:56,687 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000002_0' done.
   [druid] 2019-02-12 22:00:56,687 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000002_0
   [druid] 2019-02-12 22:00:56,687 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000003_0
   [druid] 2019-02-12 22:00:56,688 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:56,689 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:56,808 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@567fbc
   [druid] 2019-02-12 22:00:56,811 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00004:0+4641
   [druid] 2019-02-12 22:00:56,884 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:56,884 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:56,884 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:56,884 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:56,884 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:56,885 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:56,894 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:56,895 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:56,915 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:56,918 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:56,918 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000003_0' done.
   [druid] 2019-02-12 22:00:56,918 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000003_0
   [druid] 2019-02-12 22:00:56,918 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000004_0
   [druid] 2019-02-12 22:00:56,919 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:56,919 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:57,023 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 22:00:57,028 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@792dc42
   [druid] 2019-02-12 22:00:57,031 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00006:0+4489
   [druid] 2019-02-12 22:00:57,107 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:57,108 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:57,108 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:57,108 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:57,108 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:57,109 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:57,124 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:57,124 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:57,153 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:57,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:57,156 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000004_0' done.
   [druid] 2019-02-12 22:00:57,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000004_0
   [druid] 2019-02-12 22:00:57,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000005_0
   [druid] 2019-02-12 22:00:57,158 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:57,158 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:57,295 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@32473cab
   [druid] 2019-02-12 22:00:57,301 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00003:0+4260
   [druid] 2019-02-12 22:00:57,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:57,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:57,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:57,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:57,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:57,395 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:57,406 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:57,407 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:57,437 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:57,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:57,440 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000005_0' done.
   [druid] 2019-02-12 22:00:57,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000005_0
   [druid] 2019-02-12 22:00:57,441 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000006_0
   [druid] 2019-02-12 22:00:57,442 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:57,443 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:57,602 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@495eff99
   [druid] 2019-02-12 22:00:57,606 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00005:0+4260
   [druid] 2019-02-12 22:00:57,695 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:57,695 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:57,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:57,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:57,696 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:57,699 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:57,711 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:57,712 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:57,747 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:57,750 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:57,750 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000006_0' done.
   [druid] 2019-02-12 22:00:57,750 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000006_0
   [druid] 2019-02-12 22:00:57,750 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000007_0
   [druid] 2019-02-12 22:00:57,751 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:57,752 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:57,889 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2e58a5ca
   [druid] 2019-02-12 22:00:57,892 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00007:0+4260
   [druid] 2019-02-12 22:00:57,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:57,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:57,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:57,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:57,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:57,987 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:57,996 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:57,997 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:58,016 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:58,019 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:58,019 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000007_0' done.
   [druid] 2019-02-12 22:00:58,019 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000007_0
   [druid] 2019-02-12 22:00:58,019 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000008_0
   [druid] 2019-02-12 22:00:58,020 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:58,020 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:58,152 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@318df6df
   [druid] 2019-02-12 22:00:58,156 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00008:0+2867
   [druid] 2019-02-12 22:00:58,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:58,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:58,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:58,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:58,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:58,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:58,253 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:58,253 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:58,273 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:58,275 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:58,275 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000008_0' done.
   [druid] 2019-02-12 22:00:58,275 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000008_0
   [druid] 2019-02-12 22:00:58,275 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_m_000009_0
   [druid] 2019-02-12 22:00:58,276 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:58,276 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:58,394 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@39a7e9ed
   [druid] 2019-02-12 22:00:58,398 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/07/part-m-00009:0+2320
   [druid] 2019-02-12 22:00:58,498 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:00:58,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:00:58,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:00:58,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:00:58,499 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:00:58,500 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:00:58,512 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:00:58,512 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:00:58,535 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:00:58,538 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:00:58,538 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_m_000009_0' done.
   [druid] 2019-02-12 22:00:58,538 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_m_000009_0
   [druid] 2019-02-12 22:00:58,538 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 22:00:58,553 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 22:00:58,554 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1560666486_0001_r_000000_0
   [druid] 2019-02-12 22:00:58,566 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:00:58,566 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:00:58,691 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f01c37
   [druid] 2019-02-12 22:00:58,697 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@732a9913
   [druid] 2019-02-12 22:00:58,726 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 22:00:58,730 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1560666486_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 22:00:58,784 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,801 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000007_0
   [druid] 2019-02-12 22:00:58,804 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-02-12 22:00:58,820 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,821 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000004_0
   [druid] 2019-02-12 22:00:58,822 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
   [druid] 2019-02-12 22:00:58,830 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000001_0 decomp: 1038 len: 1042 to MEMORY
   [druid] 2019-02-12 22:00:58,831 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1038 bytes from map-output for attempt_local1560666486_0001_m_000001_0
   [druid] 2019-02-12 22:00:58,832 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1038, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->1042
   [druid] 2019-02-12 22:00:58,841 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,842 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000008_0
   [druid] 2019-02-12 22:00:58,842 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 1042, usedMemory ->1044
   [druid] 2019-02-12 22:00:58,849 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,850 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000005_0
   [druid] 2019-02-12 22:00:58,850 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 1044, usedMemory ->1046
   [druid] 2019-02-12 22:00:58,857 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,858 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000002_0
   [druid] 2019-02-12 22:00:58,858 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 1046, usedMemory ->1048
   [druid] 2019-02-12 22:00:58,864 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,865 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000009_0
   [druid] 2019-02-12 22:00:58,865 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 1048, usedMemory ->1050
   [druid] 2019-02-12 22:00:58,870 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,870 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000006_0
   [druid] 2019-02-12 22:00:58,871 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 1050, usedMemory ->1052
   [druid] 2019-02-12 22:00:58,877 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:00:58,878 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1560666486_0001_m_000003_0
   [druid] 2019-02-12 22:00:58,878 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 1052, usedMemory ->1054
   [druid] 2019-02-12 22:00:58,883 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1560666486_0001_m_000000_0 decomp: 1571 len: 1575 to MEMORY
   [druid] 2019-02-12 22:00:58,884 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1571 bytes from map-output for attempt_local1560666486_0001_m_000000_0
   [druid] 2019-02-12 22:00:58,884 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1571, inMemoryMapOutputs.size() -> 10, commitMemory -> 1054, usedMemory ->2625
   [druid] 2019-02-12 22:00:58,885 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 22:00:58,885 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 22:00:58,886 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 22:00:58,906 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 10 sorted segments
   [druid] 2019-02-12 22:00:58,906 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 2421 bytes
   [druid] 2019-02-12 22:00:58,910 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 10 segments, 2625 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 22:00:58,912 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2611 bytes from disk
   [druid] 2019-02-12 22:00:58,913 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 22:00:58,913 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 22:00:58,914 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2506 bytes
   [druid] 2019-02-12 22:00:58,915 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 10 / 10 copied.
   [druid] 2019-02-12 22:00:59,956 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 22:01:00,136 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1560666486_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:00,138 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 22:01:00,138 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1560666486_0001_r_000000_0' done.
   [druid] 2019-02-12 22:01:00,138 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1560666486_0001_r_000000_0
   [druid] 2019-02-12 22:01:00,139 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 22:01:00,265 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 22:01:01,024 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 22:01:01,024 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1560666486_0001 completed successfully
   [druid] 2019-02-12 22:01:01,091 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=66218
		FILE: Number of bytes written=3354370
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=859086
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=98
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=198
		Map output records=20
		Map output bytes=2565
		Map output materialized bytes=2665
		Input split bytes=1040
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=2665
		Reduce input records=20
		Reduce output records=8
		Spilled Records=40
		Shuffled Maps =10
		Failed Shuffles=0
		Merged Map outputs=10
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=8102346752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=94875
	File Output Format Counters 
		Bytes Written=0
   [druid] 2019-02-12 22:01:40,631 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-02-12 22:01:40,632 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-02-12 22:01:41,328 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-02-12 22:01:41,377 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-02-12 22:01:41,493 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 13
   [druid] 2019-02-12 22:01:41,556 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:13
   [druid] 2019-02-12 22:01:41,726 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local950719543_0001
   [druid] 2019-02-12 22:01:41,970 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-02-12 22:01:41,971 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local950719543_0001
   [druid] 2019-02-12 22:01:41,978 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-02-12 22:01:41,992 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:41,992 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-02-12 22:01:42,002 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2019-02-12 22:01:42,074 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-02-12 22:01:42,078 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000000_0
   [druid] 2019-02-12 22:01:42,134 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:42,144 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:42,263 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@70dc529b
   [druid] 2019-02-12 22:01:42,273 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00000:0+456
   [druid] 2019-02-12 22:01:42,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:42,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:42,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:42,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:42,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:42,356 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:42,841 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:42,844 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:42,875 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:42,886 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:42,886 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000000_0' done.
   [druid] 2019-02-12 22:01:42,887 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000000_0
   [druid] 2019-02-12 22:01:42,887 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000001_0
   [druid] 2019-02-12 22:01:42,888 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:42,888 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:42,975 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local950719543_0001 running in uber mode : false
   [druid] 2019-02-12 22:01:42,977 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-02-12 22:01:43,007 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6430f4ca
   [druid] 2019-02-12 22:01:43,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00002:0+452
   [druid] 2019-02-12 22:01:43,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:43,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:43,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:43,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:43,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:43,077 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:43,088 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:43,088 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:43,112 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:43,121 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:43,122 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000001_0' done.
   [druid] 2019-02-12 22:01:43,122 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000001_0
   [druid] 2019-02-12 22:01:43,122 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000002_0
   [druid] 2019-02-12 22:01:43,126 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:43,127 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:43,244 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@51ce912
   [druid] 2019-02-12 22:01:43,247 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00003:0+452
   [druid] 2019-02-12 22:01:43,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:43,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:43,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:43,320 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:43,320 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:43,321 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:43,333 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:43,333 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:43,355 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000002_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:43,360 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:43,360 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000002_0' done.
   [druid] 2019-02-12 22:01:43,361 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000002_0
   [druid] 2019-02-12 22:01:43,361 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000003_0
   [druid] 2019-02-12 22:01:43,362 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:43,363 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:43,484 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5eb432c
   [druid] 2019-02-12 22:01:43,487 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00004:0+451
   [druid] 2019-02-12 22:01:43,555 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:43,555 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:43,555 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:43,555 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:43,555 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:43,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:43,567 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:43,567 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:43,588 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000003_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:43,593 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:43,593 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000003_0' done.
   [druid] 2019-02-12 22:01:43,593 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000003_0
   [druid] 2019-02-12 22:01:43,594 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000004_0
   [druid] 2019-02-12 22:01:43,596 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:43,596 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:43,709 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@bd9f61
   [druid] 2019-02-12 22:01:43,712 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00005:0+451
   [druid] 2019-02-12 22:01:43,774 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:43,775 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:43,775 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:43,775 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:43,775 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:43,776 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:43,783 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:43,783 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:43,808 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000004_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:43,812 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:43,812 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000004_0' done.
   [druid] 2019-02-12 22:01:43,812 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000004_0
   [druid] 2019-02-12 22:01:43,812 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000005_0
   [druid] 2019-02-12 22:01:43,814 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:43,815 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:43,933 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@361a2f6f
   [druid] 2019-02-12 22:01:43,939 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00006:0+450
   [druid] 2019-02-12 22:01:44,020 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:44,020 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:44,020 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:44,020 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:44,020 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:44,022 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:44,032 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:44,032 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:44,058 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000005_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:44,060 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:44,060 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000005_0' done.
   [druid] 2019-02-12 22:01:44,060 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000005_0
   [druid] 2019-02-12 22:01:44,061 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000006_0
   [druid] 2019-02-12 22:01:44,062 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:44,062 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:44,179 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@38149342
   [druid] 2019-02-12 22:01:44,182 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00007:0+450
   [druid] 2019-02-12 22:01:44,244 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:44,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:44,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:44,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:44,245 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:44,247 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:44,263 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:44,264 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:44,286 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000006_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:44,289 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:44,290 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000006_0' done.
   [druid] 2019-02-12 22:01:44,290 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000006_0
   [druid] 2019-02-12 22:01:44,290 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000007_0
   [druid] 2019-02-12 22:01:44,292 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:44,292 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:44,404 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16c0d0d3
   [druid] 2019-02-12 22:01:44,407 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00008:0+450
   [druid] 2019-02-12 22:01:44,472 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:44,473 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:44,473 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:44,473 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:44,473 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:44,474 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:44,482 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:44,483 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:44,509 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000007_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:44,512 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:44,512 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000007_0' done.
   [druid] 2019-02-12 22:01:44,512 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000007_0
   [druid] 2019-02-12 22:01:44,512 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000008_0
   [druid] 2019-02-12 22:01:44,514 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:44,514 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:44,635 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@62cc917a
   [druid] 2019-02-12 22:01:44,638 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00009:0+450
   [druid] 2019-02-12 22:01:44,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:44,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:44,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:44,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:44,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:44,731 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:44,744 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:44,744 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:44,769 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000008_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:44,771 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:44,772 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000008_0' done.
   [druid] 2019-02-12 22:01:44,772 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000008_0
   [druid] 2019-02-12 22:01:44,772 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000009_0
   [druid] 2019-02-12 22:01:44,774 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:44,774 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:44,885 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e948617
   [druid] 2019-02-12 22:01:44,888 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00010:0+424
   [druid] 2019-02-12 22:01:44,917 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:44,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:44,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:44,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:44,918 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:44,919 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:44,926 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:44,926 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:44,946 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000009_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:44,949 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:44,949 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000009_0' done.
   [druid] 2019-02-12 22:01:44,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000009_0
   [druid] 2019-02-12 22:01:44,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000010_0
   [druid] 2019-02-12 22:01:44,952 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:44,952 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:45,073 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6dd4be3d
   [druid] 2019-02-12 22:01:45,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00011:0+424
   [druid] 2019-02-12 22:01:45,146 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:45,146 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:45,146 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:45,146 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:45,146 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:45,147 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:45,156 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:45,157 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:45,177 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000010_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:45,179 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:45,179 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000010_0' done.
   [druid] 2019-02-12 22:01:45,180 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000010_0
   [druid] 2019-02-12 22:01:45,180 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000011_0
   [druid] 2019-02-12 22:01:45,181 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:45,182 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:45,300 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@290ceae3
   [druid] 2019-02-12 22:01:45,302 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00012:0+388
   [druid] 2019-02-12 22:01:45,388 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:45,388 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:45,388 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:45,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:45,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:45,391 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:45,415 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:45,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:45,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 22:01:45,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 262; bufvoid = 104857600
   [druid] 2019-02-12 22:01:45,415 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2019-02-12 22:01:45,430 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 22:01:45,440 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000011_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:45,443 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:45,443 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000011_0' done.
   [druid] 2019-02-12 22:01:45,443 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000011_0
   [druid] 2019-02-12 22:01:45,443 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_m_000012_0
   [druid] 2019-02-12 22:01:45,444 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:45,444 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:45,555 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@564102c2
   [druid] 2019-02-12 22:01:45,558 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://min1:8020/ods/01/21/part-m-00013:0+388
   [druid] 2019-02-12 22:01:45,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-02-12 22:01:45,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-02-12 22:01:45,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-02-12 22:01:45,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-02-12 22:01:45,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-02-12 22:01:45,636 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-02-12 22:01:45,646 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-02-12 22:01:45,646 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-02-12 22:01:45,646 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-02-12 22:01:45,646 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 262; bufvoid = 104857600
   [druid] 2019-02-12 22:01:45,646 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2019-02-12 22:01:45,660 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-02-12 22:01:45,682 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_m_000012_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:45,685 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-02-12 22:01:45,685 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_m_000012_0' done.
   [druid] 2019-02-12 22:01:45,685 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_m_000012_0
   [druid] 2019-02-12 22:01:45,686 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-02-12 22:01:45,692 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-02-12 22:01:45,747 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local950719543_0001_r_000000_0
   [druid] 2019-02-12 22:01:45,762 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-02-12 22:01:45,763 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-02-12 22:01:45,899 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@21e46e5c
   [druid] 2019-02-12 22:01:45,903 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@738f5a3e
   [druid] 2019-02-12 22:01:45,926 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1319370752, maxSingleShuffleLimit=329842688, mergeThreshold=870784704, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-02-12 22:01:45,930 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local950719543_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-02-12 22:01:45,995 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000012_0 decomp: 268 len: 272 to MEMORY
   [druid] 2019-02-12 22:01:46,001 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 268 bytes from map-output for attempt_local950719543_0001_m_000012_0
   [druid] 2019-02-12 22:01:46,004 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 268, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->268
   [druid] 2019-02-12 22:01:46,013 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,014 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000006_0
   [druid] 2019-02-12 22:01:46,014 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 268, usedMemory ->270
   [druid] 2019-02-12 22:01:46,022 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,024 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000005_0
   [druid] 2019-02-12 22:01:46,024 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 270, usedMemory ->272
   [druid] 2019-02-12 22:01:46,032 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,033 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000004_0
   [druid] 2019-02-12 22:01:46,033 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 272, usedMemory ->274
   [druid] 2019-02-12 22:01:46,040 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000011_0 decomp: 268 len: 272 to MEMORY
   [druid] 2019-02-12 22:01:46,041 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 268 bytes from map-output for attempt_local950719543_0001_m_000011_0
   [druid] 2019-02-12 22:01:46,042 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 268, inMemoryMapOutputs.size() -> 5, commitMemory -> 274, usedMemory ->542
   [druid] 2019-02-12 22:01:46,049 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000010_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,050 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000010_0
   [druid] 2019-02-12 22:01:46,050 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 542, usedMemory ->544
   [druid] 2019-02-12 22:01:46,055 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,056 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000009_0
   [druid] 2019-02-12 22:01:46,056 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 544, usedMemory ->546
   [druid] 2019-02-12 22:01:46,061 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,062 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000003_0
   [druid] 2019-02-12 22:01:46,062 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 546, usedMemory ->548
   [druid] 2019-02-12 22:01:46,067 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,068 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000008_0
   [druid] 2019-02-12 22:01:46,068 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 548, usedMemory ->550
   [druid] 2019-02-12 22:01:46,078 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,079 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000002_0
   [druid] 2019-02-12 22:01:46,079 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 550, usedMemory ->552
   [druid] 2019-02-12 22:01:46,084 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,085 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000001_0
   [druid] 2019-02-12 22:01:46,085 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 11, commitMemory -> 552, usedMemory ->554
   [druid] 2019-02-12 22:01:46,090 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,091 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000000_0
   [druid] 2019-02-12 22:01:46,092 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 12, commitMemory -> 554, usedMemory ->556
   [druid] 2019-02-12 22:01:46,096 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local950719543_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-02-12 22:01:46,097 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local950719543_0001_m_000007_0
   [druid] 2019-02-12 22:01:46,097 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 13, commitMemory -> 556, usedMemory ->558
   [druid] 2019-02-12 22:01:46,098 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-02-12 22:01:46,098 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 13 / 13 copied.
   [druid] 2019-02-12 22:01:46,099 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 13 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-02-12 22:01:46,121 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 13 sorted segments
   [druid] 2019-02-12 22:01:46,122 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 336 bytes
   [druid] 2019-02-12 22:01:46,127 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 13 segments, 558 bytes to disk to satisfy reduce memory limit
   [druid] 2019-02-12 22:01:46,128 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 538 bytes from disk
   [druid] 2019-02-12 22:01:46,128 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-02-12 22:01:46,128 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-02-12 22:01:46,129 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 434 bytes
   [druid] 2019-02-12 22:01:46,129 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 13 / 13 copied.
   [druid] 2019-02-12 22:01:46,595 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-02-12 22:01:46,672 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local950719543_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-02-12 22:01:46,673 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-02-12 22:01:46,673 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local950719543_0001_r_000000_0' done.
   [druid] 2019-02-12 22:01:46,673 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local950719543_0001_r_000000_0
   [druid] 2019-02-12 22:01:46,673 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-02-12 22:01:46,799 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2019-02-12 22:01:46,983 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-02-12 22:01:46,983 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local950719543_0001 completed successfully
   [druid] 2019-02-12 22:01:47,020 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=120266
		FILE: Number of bytes written=4216628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=46411
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=146
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=4
		Map output bytes=524
		Map output materialized bytes=610
		Input split bytes=1352
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=610
		Reduce input records=4
		Reduce output records=2
		Spilled Records=8
		Shuffled Maps =13
		Failed Shuffles=0
		Merged Map outputs=13
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=12493783040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5686
	File Output Format Counters 
		Bytes Written=0
   